{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Octocat\" src='./img/Octocat.jpg' style='height: 60px; padding-right: 15px' alt=\"Octocat\" align=\"left\"> This notebook is part of a GitHub repository: https://github.com/pessini/moby-bikes \n",
    "<br>MIT Licensed\n",
    "<br>Author: Leandro Pessini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model and Evaluation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# spicy\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import yeojohnson\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python version:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Leandro Pessini\n",
      "\n",
      "sklearn    : 0.24.2\n",
      "sys        : 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:36:15) \n",
      "[Clang 11.1.0 ]\n",
      "numpy      : 1.21.1\n",
      "pandas     : 1.3.0\n",
      "seaborn    : 0.11.1\n",
      "statsmodels: 0.12.2\n",
      "scipy      : 1.7.0\n",
      "matplotlib : 3.4.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Leandro Pessini\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_date</th>\n",
       "      <th>rental_hour</th>\n",
       "      <th>rental_day</th>\n",
       "      <th>rental_month</th>\n",
       "      <th>rental_year</th>\n",
       "      <th>holiday</th>\n",
       "      <th>dayofweek_n</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>working_day</th>\n",
       "      <th>season</th>\n",
       "      <th>peak</th>\n",
       "      <th>timesofday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rhum</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>rain_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>True</td>\n",
       "      <td>Winter</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>no rain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>True</td>\n",
       "      <td>Winter</td>\n",
       "      <td>True</td>\n",
       "      <td>Morning</td>\n",
       "      <td>2.1</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>no rain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>True</td>\n",
       "      <td>Winter</td>\n",
       "      <td>True</td>\n",
       "      <td>Morning</td>\n",
       "      <td>5.1</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>no rain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>True</td>\n",
       "      <td>Winter</td>\n",
       "      <td>True</td>\n",
       "      <td>Morning</td>\n",
       "      <td>5.7</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>no rain</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>True</td>\n",
       "      <td>Winter</td>\n",
       "      <td>True</td>\n",
       "      <td>Morning</td>\n",
       "      <td>6.7</td>\n",
       "      <td>94</td>\n",
       "      <td>6</td>\n",
       "      <td>no rain</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rental_date  rental_hour  rental_day  rental_month  rental_year  holiday  \\\n",
       "0  2021-03-01            2           1             3         2021    False   \n",
       "1  2021-03-01            7           1             3         2021    False   \n",
       "2  2021-03-01            8           1             3         2021    False   \n",
       "3  2021-03-01            9           1             3         2021    False   \n",
       "4  2021-03-01           10           1             3         2021    False   \n",
       "\n",
       "   dayofweek_n dayofweek  working_day  season   peak timesofday  temp  rhum  \\\n",
       "0            0    Monday         True  Winter  False      Night  -1.2    98   \n",
       "1            0    Monday         True  Winter   True    Morning   2.1   100   \n",
       "2            0    Monday         True  Winter   True    Morning   5.1    98   \n",
       "3            0    Monday         True  Winter   True    Morning   5.7    98   \n",
       "4            0    Monday         True  Winter   True    Morning   6.7    94   \n",
       "\n",
       "   wdsp rain_type  count  \n",
       "0     4   no rain      1  \n",
       "1     4   no rain      3  \n",
       "2     5   no rain      1  \n",
       "3     5   no rain      4  \n",
       "4     6   no rain      4  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data = pd.read_csv('../data/processed/hourly_data.csv')\n",
    "hourly_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Assumptions\n",
    "\n",
    "- Linearity\n",
    "- Normality of the Error\n",
    "- No Multicollinearity among Predictors\n",
    "- No Autocorrelation of the Error Terms\n",
    "- Homoscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourlyDataWithoutOutliers = hourly_data[np.abs(hourly_data[\"count\"]-hourly_data[\"count\"].mean())<=(2*hourly_data[\"count\"].std())] \n",
    "# df = hourlyDataWithoutOutliers.copy()\n",
    "df = hourly_data.copy()\n",
    "df = df.astype({'holiday': 'category', \n",
    "                'dayofweek': 'category', \n",
    "                'working_day': 'category',\n",
    "                'rental_hour': 'category',\n",
    "                'season': 'category',\n",
    "                'peak': 'category',\n",
    "                'timesofday': 'category'})\n",
    "predictors = ['temp','wdsp','rhum','rain_type','holiday','season','dayofweek','working_day','peak','timesofday']\n",
    "\n",
    "# OrdinalEnconder was chosen due \n",
    "enc = OrdinalEncoder(dtype=np.int64, categories=[['no rain', 'drizzle', 'light rain', 'moderate rain', 'heavy rain']])\n",
    "df['rain_type'] = enc.fit_transform(df[['rain_type']])\n",
    "\n",
    "X = df[[c for c in df.columns if c in predictors]]\n",
    "y = df.pop('count')\n",
    "\n",
    "# X['rain_type'] = pd.to_numeric(X['rain_type'])\n",
    "\n",
    "num_vars = [n for n in df.select_dtypes(include=['number']).columns if n in predictors] # list comprehension to select only predictors features\n",
    "cat_vars = [c for c in df.select_dtypes(include=['category']).columns if c in predictors]\n",
    "\n",
    "dummies = pd.get_dummies(X[cat_vars], drop_first=True)\n",
    "X = pd.concat([X[num_vars], dummies],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_constant = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_with_constant)\n",
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2_score(X, r2_score):\n",
    "    return 1 - ( 1- r2_score ) * ( len(X) - 1 ) / ( len(X) - X.shape[1] - 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evalmetrics(actual, predicted):\n",
    "    print('RMSE:', metrics.mean_squared_error(actual, predicted, squared=False))\n",
    "    print('MAE:', metrics.mean_absolute_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals(model, features, label):\n",
    "    \"\"\"\n",
    "    Creates predictions on the features with the model and calculates residuals\n",
    "    \"\"\"\n",
    "    predictions = model.predict(features)\n",
    "    df_results = pd.DataFrame({'Actual': label, 'Predicted': predictions})\n",
    "    df_results['Residuals'] = abs(df_results['Actual']) - abs(df_results['Predicted'])\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def linear_assumption(model, features, label):\n",
    "    \"\"\"\n",
    "    Linearity: Assumes that there is a linear relationship between the predictors and\n",
    "               the response variable. If not, either a quadratic term or another\n",
    "               algorithm should be used.\n",
    "    \"\"\"\n",
    "    print('Assumption 1: Linear Relationship between the Target and the Feature', '\\n')\n",
    "        \n",
    "    print('Checking with a scatter plot of actual vs. predicted.',\n",
    "           'Predictions should follow the diagonal line.')\n",
    "    \n",
    "    # Calculating residuals for the plot\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "    \n",
    "    # Plotting the actual vs predicted values\n",
    "    sns.lmplot(x='Actual', y='Predicted', data=df_results, fit_reg=False, size=7)\n",
    "        \n",
    "    # Plotting the diagonal line\n",
    "    line_coords = np.arange(df_results.min().min(), df_results.max().max())\n",
    "    plt.plot(line_coords, line_coords,  # X and y points\n",
    "             color='darkorange', linestyle='--')\n",
    "    plt.title('Actual vs. Predicted')\n",
    "    plt.show()\n",
    "    print('If non-linearity is apparent, consider adding a polynomial term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting the model\n",
    "# linear_model = LinearRegression()\n",
    "# linear_model.fit(X_train, y_train)\n",
    "\n",
    "# # Returning the R^2 for the model\n",
    "# linear_model_r2 = linear_model.score(X_train, y_train)\n",
    "# print('R^2: {0}'.format(linear_model_r2))\n",
    "# print_evalmetrics(y_test, linear_model.predict(X_test))\n",
    "# linear_assumption(linear_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Polynomial Regression to the dataset\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly = PolynomialFeatures(degree = 5)\n",
    "# X_poly = poly.fit_transform(X_train) \n",
    "# # poly.fit(X_poly, y_train)\n",
    "# lin2 = LinearRegression()\n",
    "# lin2.fit(X_poly, y_train)\n",
    "# linear_assumption(lin2, X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sm.add_constant(X_test)\n",
    "y_pred = results.predict(X_test)\n",
    "residual = y_test - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.mean(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and Multicollinearity between Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36610ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "Autumn     9.625675\n",
       "Spring    10.427230\n",
       "Summer    15.723227\n",
       "Winter     6.729032\n",
       "Name: temp, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hourly_rentals.groupby('season')['temp'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc7dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6966.000000\n",
       "mean       10.742392\n",
       "std         5.002159\n",
       "min        -4.000000\n",
       "25%         7.025000\n",
       "50%        10.600000\n",
       "75%        14.500000\n",
       "max        26.300000\n",
       "Name: temp, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hourly_rentals['temp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_temp = hourly_rentals.copy()\n",
    "hourly_data_temp['temp_type'] =  np.where(hourly_data_temp['temp'] > 10, 'High', 'Low')\n",
    "hourly_data_temp['prodTempWind'] = hourly_data_temp['temp']*hourly_data_temp['wdsp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07050e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_temp.groupby('temp_type')['temp'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ee080",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = sns.pairplot(hourly_data_temp, \n",
    "             x_vars='prodTempWind',\n",
    "             dropna=True, hue='temp_type',\n",
    "             y_vars='count', height=8, aspect=0.8, kind=\"reg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8263841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import yeojohnson\n",
    "corr = hourly_data_temp['temp'].corr(hourly_data_temp['prodTempWind'])\n",
    "fig,ax = plt.subplots(figsize=(13, 5))\n",
    "sns.distplot(hourly_data_temp['prodTempWind'], \n",
    "             label= 'prodTempWind Skew :{0}'.format(np.round(skew(hourly_data_temp['prodTempWind']),4)), \n",
    "             color='r', ax=ax, axlabel='prodTempWind')\n",
    "ax.set(title='Distribution of prodTempWind Variable')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly_data_temp['prodTempWind']\n",
    "# yf_target = np.cbrt(hourly_data_temp['prodTempWind'])\n",
    "yf_target, lam = yeojohnson(hourly_data_temp['prodTempWind'])\n",
    "fig,ax = plt.subplots(figsize=(13, 5))\n",
    "sns.distplot(yf_target, label= 'Transformed Skew:{0}'.format(np.round(skew(yf_target),4)), color='g', ax=ax, axlabel='BOX-COX TRANSFORMED')\n",
    "ax.set(title='Distribution of prodTempWind after Box-Cox transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e01cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_temp['prodRainWind'] = hourly_data_temp['rain']+hourly_data_temp['wdsp']\n",
    "# sqrrt_target = hourly_data['prodRainWind']**(1/2)\n",
    "corr = hourly_data_temp['rain'].corr(hourly_data_temp['prodRainWind'])\n",
    "fig,ax = plt.subplots(figsize=(13, 5))\n",
    "sns.distplot(hourly_data_temp['prodRainWind'], \n",
    "             label= 'prodRainWind Skew :{0}'.format(np.round(skew(hourly_data_temp['prodRainWind']),4)), \n",
    "             color='r', ax=ax, axlabel='prodRainWind')\n",
    "ax.set(title='Distribution of prodRainWind Variable')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcx_target, lam = boxcox(hourly_data_temp['prodRainWind'])\n",
    "fig,ax = plt.subplots(1,2,figsize=(13, 5))\n",
    "sns.distplot(hourly_data_temp['prodRainWind'], label= 'Orginal Skew :{0}'.format(np.round(skew(hourly_data_temp['prodRainWind']),4)), color='r', ax=ax[0], axlabel='ORGINAL')\n",
    "sns.distplot(bcx_target, label= 'Transformed Skew:{0}'.format(np.round(skew(bcx_target),4)), color='g', ax=ax[1], axlabel='BOX-COX TRANSFORMED')\n",
    "ax[0].set(title='Distribution of Target Variable')\n",
    "ax[1].set(title='After Transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_target, lam = yeojohnson(hourly_data_temp['prodRainWind'])\n",
    "fig,ax = plt.subplots(1,2,figsize=(13, 5))\n",
    "sns.distplot(hourly_data_temp['prodRainWind'], label= 'Orginal Skew :{0}'.format(np.round(skew(hourly_data_temp['prodRainWind']),4)), color='r', ax=ax[0], axlabel='ORGINAL')\n",
    "sns.distplot(yf_target, label= 'Transformed Skew:{0}'.format(np.round(skew(yf_target),4)), color='g', ax=ax[1], axlabel='Y-J TRANSFORMED')\n",
    "ax[0].set(title='Distribution of Target Variable')\n",
    "ax[1].set(title='After Transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b20e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatt = hourly_data_temp[['temp','prodTempWind','rhum','prodRainWind','wdsp', 'dew_point','count']].corr()\n",
    "mask = np.array(corrMatt)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corrMatt, mask=mask,vmax=.3, annot=True, ax=ax, cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c547bf78",
   "metadata": {},
   "source": [
    "\n",
    "### Wind Speed Beaufort scale\n",
    "\n",
    "https://www.metoffice.gov.uk/weather/guides/coast-and-sea/beaufort-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae838b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def scale(value, factor):\n",
    "    \"\"\"\n",
    "    Multiply value by factor, allowing for None values.\n",
    "    \"\"\"\n",
    "    return None if value is None else value * factor\n",
    "\n",
    "def wind_ms(kn):\n",
    "    \"\"\"\n",
    "    Convert wind from knots to metres per second\n",
    "    \"\"\"\n",
    "    return scale(kn, 0.514)\n",
    "\n",
    "def wind_kn(ms):\n",
    "    \"\"\"\n",
    "    Convert wind from metres per second to knots\n",
    "    \"\"\"\n",
    "    return scale(ms, 3.6 / 1.852)\n",
    "\n",
    "def wind_bft(ms):\n",
    "    \"\"\"\n",
    "    Convert wind from metres per second to Beaufort scale\n",
    "    \"\"\"\n",
    "    _bft_threshold = (0.3, 1.5, 3.4, 5.4, 7.9, 10.7, 13.8, 17.1, 20.7, 24.4, 28.4, 32.6)\n",
    "    if ms is None:\n",
    "        return None\n",
    "    return next((bft for bft in range(len(_bft_threshold)) if ms < _bft_threshold[bft]), len(_bft_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fe475",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_temp['wind_bft'] = hourly_data_temp.apply(lambda row: wind_bft(wind_ms(row.wdsp)), axis=1)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.barplot(data=hourly_data_temp, x='wind_bft', y='count', ci=None)\n",
    "ax.set(xlabel='Number of Rentals', ylabel='Period of the Day', title='Rentals across Times of the Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11082f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data_temp['wdsp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewtest\n",
    "# skewtest(hourly_data_temp['prodTempWind'])\n",
    "# skewtest(sqrrt_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.histplot(data=hourly_rentals, x='wdsp', kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_target = np.log1p(hourly_data['count'])\n",
    "# log_target = np.log1p(hourly_data['count'].sample(frac=0.2, replace=False))\n",
    "fig,ax = plt.subplots(1,2,figsize=(13, 5))\n",
    "sns.distplot(hourly_data['count'], label= 'Orginal Skew:{0}'.format(np.round(skew(hourly_data['count']),4)), color='r', ax=ax[0], axlabel='ORGINAL')\n",
    "sns.distplot(log_target, label= 'Transformed Skew:{0}'.format(np.round(skew(log_target),4)), color='g', ax=ax[1], axlabel='LOG TRANSFORMED')\n",
    "ax[0].set(title='Distribution of Target Variable')\n",
    "ax[1].set(title='After Transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square Root Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrrt_target = hourly_data['count']**(1/2)\n",
    "fig,ax = plt.subplots(1,2,figsize=(13, 5))\n",
    "sns.distplot(hourly_data['count'], label= 'Orginal Skew:{0}'.format(np.round(skew(hourly_data['count']),4)), color='r', ax=ax[0], axlabel='ORGINAL')\n",
    "sns.distplot(sqrrt_target, label= 'Transformed Skew:{0}'.format(np.round(skew(sqrrt_target),4)), color='g', ax=ax[1], axlabel='SQUARE ROOT TRANSFORMED')\n",
    "ax[0].set(title='Distribution of Target Variable')\n",
    "ax[1].set(title='After Transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciprocal Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_target = 1/hourly_data['count']\n",
    "fig,ax = plt.subplots(1,2,figsize=(13, 5))\n",
    "sns.distplot(hourly_data['count'], label= 'Orginal Skew :{0}'.format(np.round(skew(hourly_data['count']),4)), color='r', ax=ax[0], axlabel='ORGINAL')\n",
    "sns.distplot(re_target, label= 'Transformed Skew:{0}'.format(np.round(skew(re_target),4)), color='g', ax=ax[1], axlabel='INVERSE TRANSFORMED')\n",
    "ax[0].set(title='Distribution of Target Variable')\n",
    "ax[1].set(title='After Transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box-cox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcx_target, lam = boxcox(hourly_data['count'])\n",
    "fig,ax = plt.subplots(1,2,figsize=(13, 5))\n",
    "sns.distplot(hourly_data['count'], label= 'Orginal Skew :{0}'.format(np.round(skew(hourly_data['count']),4)), color='r', ax=ax[0], axlabel='ORGINAL')\n",
    "sns.distplot(bcx_target, label= 'Transformed Skew:{0}'.format(np.round(skew(bcx_target),4)), color='g', ax=ax[1], axlabel='BOX-COX TRANSFORMED')\n",
    "ax[0].set(title='Distribution of Target Variable')\n",
    "ax[1].set(title='After Transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeo-Johnson Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf_target, lam = yeojohnson(hourly_data['count'])\n",
    "fig,ax = plt.subplots(1,2,figsize=(13, 5))\n",
    "sns.distplot(hourly_data['count'], label= 'Orginal Skew :{0}'.format(np.round(skew(hourly_data['count']),4)), color='r', ax=ax[0], axlabel='ORGINAL')\n",
    "sns.distplot(yf_target, label= 'Transformed Skew:{0}'.format(np.round(skew(yf_target),4)), color='g', ax=ax[1], axlabel='Y-J TRANSFORMED')\n",
    "ax[0].set(title='Distribution of Target Variable')\n",
    "ax[1].set(title='After Transformation')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicolinearity\n",
    "vif = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "pd.DataFrame({'vif': vif[0:]}, index=X_train.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(residual, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "fig, ax = plt.subplots(figsize=(6,2.5))\n",
    "_, (__, ___, r) = sp.stats.probplot(residual, plot=ax, fit=True)\n",
    "np.mean(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,2.5))\n",
    "_ = ax.scatter(y_pred, residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(22,6))\n",
    "acf = smt.graphics.plot_acf(residual, lags=40 , alpha=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning the R^2 for the model\n",
    "linear_r2 = pipe_linear_regression.score(X_train, y_train)\n",
    "print('R^2: {0}'.format(linear_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_residuals(model, features, label):\n",
    "    \"\"\"\n",
    "    Creates predictions on the features with the model and calculates residuals\n",
    "    \"\"\"\n",
    "    predictions = model.predict(features)\n",
    "    df_results = pd.DataFrame({'Actual': label, 'Predicted': predictions})\n",
    "    df_results['Residuals'] = abs(df_results['Actual']) - abs(df_results['Predicted'])\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_assumption(model, features, label):\n",
    "    \"\"\"\n",
    "    Linearity: Assumes that there is a linear relationship between the predictors and\n",
    "               the response variable. If not, either a quadratic term or another\n",
    "               algorithm should be used.\n",
    "    \"\"\"\n",
    "    print('Assumption 1: Linear Relationship between the Target and the Feature', '\\n')\n",
    "        \n",
    "    print('Checking with a scatter plot of actual vs. predicted.',\n",
    "           'Predictions should follow the diagonal line.')\n",
    "    \n",
    "    # Calculating residuals for the plot\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "    \n",
    "    # Plotting the actual vs predicted values\n",
    "    sns.lmplot(x='Actual', y='Predicted', data=df_results, fit_reg=False, height=7)\n",
    "        \n",
    "    # Plotting the diagonal line\n",
    "    line_coords = np.arange(df_results.min().min(), df_results.max().max())\n",
    "    plt.plot(line_coords, line_coords,  # X and y points\n",
    "             color='darkorange', linestyle='--')\n",
    "    plt.title('Actual vs. Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_assumption(pipe_linear_regression, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality of the Error Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_errors_assumption(model, features, label, p_value_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "    nonlinear transformations of variables may solve this.\n",
    "               \n",
    "    This assumption being violated primarily causes issues with the confidence intervals\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.diagnostic import normal_ad\n",
    "    print('Assumption 2: The error terms are normally distributed', '\\n')\n",
    "    \n",
    "    # Calculating residuals for the Anderson-Darling test\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "    \n",
    "    print('Using the Anderson-Darling test for normal distribution')\n",
    "\n",
    "    # Performing the test on the residuals\n",
    "    p_value = normal_ad(df_results['Residuals'])[1]\n",
    "    print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "    \n",
    "    # Reporting the normality of the residuals\n",
    "    if p_value < p_value_thresh:\n",
    "        print('Residuals are not normally distributed')\n",
    "    else:\n",
    "        print('Residuals are normally distributed')\n",
    "    \n",
    "    # Plotting the residuals distribution\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    plt.title('Distribution of Residuals')\n",
    "    sns.histplot(df_results['Residuals'], kde=True) \n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    if p_value > p_value_thresh:\n",
    "        print('Assumption satisfied')\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Confidence intervals will likely be affected')\n",
    "        print('Try performing nonlinear transformations on variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_errors_assumption(pipe_linear_regression, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Multicollinearity among Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicollinearity_assumption(model, features, label, feature_names=None):\n",
    "    \"\"\"\n",
    "    Multicollinearity: Assumes that predictors are not correlated with each other. If there is\n",
    "                       correlation among the predictors, then either remove prepdictors with high\n",
    "                       Variance Inflation Factor (VIF) values or perform dimensionality reduction\n",
    "                           \n",
    "                       This assumption being violated causes issues with interpretability of the \n",
    "                       coefficients and the standard errors of the coefficients.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    print('Assumption 3: Little to no multicollinearity among predictors')\n",
    "\n",
    "    # Plotting the heatmap\n",
    "    plt.figure(figsize = (10,8))\n",
    "    sns.heatmap(pd.DataFrame(features, columns=feature_names).corr(), annot=True)\n",
    "    plt.title('Correlation of Variables')\n",
    "    plt.show()\n",
    "\n",
    "    print('Variance Inflation Factors (VIF)')\n",
    "    print('> 10: An indication that multicollinearity may be present')\n",
    "    print('> 100: Certain multicollinearity among the variables')\n",
    "    print('-------------------------------------')\n",
    "\n",
    "    # Gathering the VIF for each variable\n",
    "    VIF = [variance_inflation_factor(features, i) for i in range(features.shape[1])]\n",
    "    for idx, vif in enumerate(VIF):\n",
    "        print('{0}: {1}'.format(feature_names[idx], vif))\n",
    "\n",
    "    # Gathering and printing total cases of possible or definite multicollinearity\n",
    "    possible_multicollinearity = sum(vif > 10 for vif in VIF)\n",
    "    definite_multicollinearity = sum(vif > 100 for vif in VIF)\n",
    "    print()\n",
    "    print('{0} cases of possible multicollinearity'.format(possible_multicollinearity))\n",
    "    print('{0} cases of definite multicollinearity'.format(definite_multicollinearity))\n",
    "    print()\n",
    "\n",
    "    if definite_multicollinearity == 0:\n",
    "        if possible_multicollinearity == 0:\n",
    "            print('Assumption satisfied')\n",
    "        else:\n",
    "            print('Assumption possibly satisfied')\n",
    "            print()\n",
    "            print('Coefficient interpretability may be problematic')\n",
    "            print('Consider removing variables with a high Variance Inflation Factor (VIF)')\n",
    "\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Coefficient interpretability will be problematic')\n",
    "        print('Consider removing variables with a high Variance Inflation Factor (VIF)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicollinearity_assumption(pipe_linear_regression, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Autocorrelation of the Error Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation_assumption(model, features, label):\n",
    "    \"\"\"\n",
    "    Autocorrelation: Assumes that there is no autocorrelation in the residuals. If there is\n",
    "                     autocorrelation, then there is a pattern that is not explained due to\n",
    "                     the current value being dependent on the previous value.\n",
    "                     This may be resolved by adding a lag variable of either the dependent\n",
    "                     variable or some of the predictors.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.stattools import durbin_watson\n",
    "    print('Assumption 4: No Autocorrelation', '\\n')\n",
    "    \n",
    "    # Calculating residuals for the Durbin Watson-tests\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "\n",
    "    print('\\nPerforming Durbin-Watson Test')\n",
    "    print('Values of 1.5 < d < 2.5 generally show that there is no autocorrelation in the data')\n",
    "    print('0 to 2< is positive autocorrelation')\n",
    "    print('>2 to 4 is negative autocorrelation')\n",
    "    print('-------------------------------------')\n",
    "    durbinWatson = durbin_watson(df_results['Residuals'])\n",
    "    print('Durbin-Watson:', durbinWatson)\n",
    "    if durbinWatson < 1.5:\n",
    "        print('Signs of positive autocorrelation', '\\n')\n",
    "        print('Assumption not satisfied')\n",
    "    elif durbinWatson > 2.5:\n",
    "        print('Signs of negative autocorrelation', '\\n')\n",
    "        print('Assumption not satisfied')\n",
    "    else:\n",
    "        print('Little to no autocorrelation', '\\n')\n",
    "        print('Assumption satisfied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_assumption(pipe_linear_regression, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homoscedasticity_assumption(model, features, label):\n",
    "    \"\"\"\n",
    "    Homoscedasticity: Assumes that the errors exhibit constant variance\n",
    "    \"\"\"\n",
    "    print('Assumption 5: Homoscedasticity of Error Terms', '\\n')\n",
    "    \n",
    "    print('Residuals should have relative constant variance')\n",
    "        \n",
    "    # Calculating residuals for the plot\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "\n",
    "    # Plotting the residuals\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    ax = plt.subplot(111)  # To remove spines\n",
    "    plt.scatter(x=df_results.index, y=df_results.Residuals, alpha=0.5)\n",
    "    plt.plot(np.repeat(0, df_results.index.max()), color='darkorange', linestyle='--')\n",
    "    ax.spines['right'].set_visible(False)  # Removing the right spine\n",
    "    ax.spines['top'].set_visible(False)  # Removing the top spine\n",
    "    plt.title('Residuals')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homoscedasticity_assumption(pipe_linear_regression, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c82cf216bcd6695c751af4e033b89e10a78cc5d50e2943f0ed5dd08b475eddb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('conda-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
