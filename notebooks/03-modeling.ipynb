{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Octocat\" src='./img/Octocat.jpg' style='height: 60px; padding-right: 15px' alt=\"Octocat\" align=\"left\"> This notebook is part of a GitHub repository: https://github.com/pessini/moby-bikes \n",
    "<br>MIT Licensed\n",
    "<br>Author: Leandro Pessini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Models</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Table of Contents:</p>\n",
    "* [1. Datasets](#1)\n",
    "  * [1.1 Rentals Data - Moby Bikes](#1.1)\n",
    "  * [1.2 Weather Data - Met Ã‰ireann](#1.2)\n",
    "* [2. Preprocessing & Feature Engineering](#2)\n",
    "  * [2.1 Target variable distribution](#2.1)\n",
    "  * [2.2 Missing values](#2.2)\n",
    "  * [2.3 Exploratory Analysis](#2.3)\n",
    "  * [2.4 Features Importance](#2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models & Evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats as stats\n",
    "\n",
    "# Boost models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cat\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Hyperparameter optimization\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Python version:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Leandro Pessini\n",
      "\n",
      "catboost   : 0.26.1\n",
      "pandas     : 1.3.0\n",
      "lightgbm   : 3.2.1\n",
      "xgboost    : 1.4.0\n",
      "sys        : 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:36:15) \n",
      "[Clang 11.1.0 ]\n",
      "seaborn    : 0.11.1\n",
      "sklearn    : 1.0.2\n",
      "numpy      : 1.21.1\n",
      "statsmodels: 0.12.2\n",
      "matplotlib : 3.4.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Leandro Pessini\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8760, 21), (6966, 21))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data = pd.read_csv('../data/processed/hourly_data.csv')\n",
    "hourly_rentals = pd.read_csv('../data/processed/hourly_rentals.csv')\n",
    "hourly_data.shape, hourly_rentals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6132, 12), (2628, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hourly_data.copy()\n",
    "# df = hourly_rentals.copy()\n",
    "df = df.astype({'holiday': 'category',\n",
    "                'working_day': 'category',\n",
    "                'peak': 'category',\n",
    "                'season': 'category',\n",
    "                'dayofweek': 'category',\n",
    "                'timesofday': 'category',\n",
    "                'rainfall_intensity': 'category',\n",
    "                'wind_bft': 'category',\n",
    "                'wind_speed_group': 'category'})\n",
    "\n",
    "df['humidity_norm'] = df['rhum']/100\n",
    "# predictors = ['temp_r','wind_speed_group','humidity_norm','rainfall_intensity','holiday','season','dayofweek','working_day','peak','timesofday']\n",
    "predictors = ['temp_r','wind_speed_group','rhum','rainfall_intensity','holiday','peak','timesofday']\n",
    "\n",
    "# OrdinalEnconder\n",
    "enc_rain = OrdinalEncoder(dtype=np.int64, \\\n",
    "    categories=[['no rain', 'drizzle', 'light rain', 'moderate rain', 'heavy rain']])\n",
    "df['rainfall_intensity'] = enc_rain.fit_transform(df[['rainfall_intensity']])\n",
    "\n",
    "enc_wind = OrdinalEncoder(dtype=np.int64, \\\n",
    "    categories=[['Calm / Light Breeze', 'Breeze', 'Moderate Breeze', 'Strong Breeze / Near Gale','Gale / Storm']])\n",
    "df['wind_speed_group'] = enc_wind.fit_transform(df[['wind_speed_group']])\n",
    "\n",
    "X = df[[c for c in df.columns if c in predictors]]\n",
    "y = df.pop('count')\n",
    "\n",
    "num_vars = [n for n in df.select_dtypes(include=['number']).columns if n in predictors] # list comprehension to select only predictors features\n",
    "cat_vars = [c for c in df.select_dtypes(include=['category']).columns if c in predictors]\n",
    "\n",
    "dummies = pd.get_dummies(X[cat_vars], drop_first=False)\n",
    "X = pd.concat([X[num_vars], dummies],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6132 entries, 1444 to 7270\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   rhum                  6132 non-null   int64\n",
      " 1   rainfall_intensity    6132 non-null   int64\n",
      " 2   wind_speed_group      6132 non-null   int64\n",
      " 3   temp_r                6132 non-null   int64\n",
      " 4   holiday_False         6132 non-null   uint8\n",
      " 5   holiday_True          6132 non-null   uint8\n",
      " 6   peak_False            6132 non-null   uint8\n",
      " 7   peak_True             6132 non-null   uint8\n",
      " 8   timesofday_Afternoon  6132 non-null   uint8\n",
      " 9   timesofday_Evening    6132 non-null   uint8\n",
      " 10  timesofday_Morning    6132 non-null   uint8\n",
      " 11  timesofday_Night      6132 non-null   uint8\n",
      "dtypes: int64(4), uint8(8)\n",
      "memory usage: 287.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split columns in categorical and numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: ['rhum', 'rainfall_intensity', 'wind_speed_group', 'temp_r']\n",
      "Categorical features: ['holiday', 'peak', 'timesofday']\n",
      "Ordinal features: ['rainfall_intensity']\n"
     ]
    }
   ],
   "source": [
    "num_vars = [n for n in df.select_dtypes(include=['number']).columns if n in predictors]\n",
    "cat_vars = [c for c in df.select_dtypes(include=['category']).columns if c in predictors]\n",
    "# nu\n",
    "ord_var = ['rainfall_intensity']\n",
    "print(f'Numerical features: {num_vars}')\n",
    "print(f'Categorical features: {cat_vars}')\n",
    "print(f'Ordinal features: {ord_var}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical pipeline\n",
    "cat_pipe = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "# Define numerical pipeline\n",
    "num_pipe = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    # ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "ord_pipe = Pipeline([\n",
    "    ('ordinal_enconder', OrdinalEncoder(dtype=np.int64, categories=[['no rain', \n",
    "                                                                     'drizzle', \n",
    "                                                                     'light rain', \n",
    "                                                                     'moderate rain', \n",
    "                                                                     'heavy rain']]))\n",
    "])\n",
    "\n",
    "# Combine categorical and numerical pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipe, cat_vars),\n",
    "    ('ordinal_enconder', ord_pipe, ord_var),\n",
    "    ('num', num_pipe, num_vars)\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmsle(y_pred, y_actual):\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evalmetrics(actual, predicted):\n",
    "    print('RMSLE:', get_rmsle(actual, predicted))\n",
    "    # print('MAE:', metrics.mean_absolute_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Discrete Dependent VariableÂ¶\n",
    "\n",
    "\n",
    "Regression models for limited and qualitative dependent variables. Count (Poisson, NegativeBinomial) data.\n",
    "\n",
    "- Poisson / Zero-Inflated Poisson (ZIP)\n",
    "- Negative Binomial / Zero-Inflated Negative Binomial (ZINB)\n",
    "\n",
    "### statsmodels library\n",
    "\n",
    "- `Poisson()` - Poisson Model\n",
    "- `NegativeBinomial()` - Negative Binomial Model\n",
    "- `NegativeBinomialP()` - Generalized Negative Binomial (NB-P) Model\n",
    "- `GeneralizedPoisson()` - Generalized Poisson Model\n",
    "- `ZeroInflatedPoisson()` - Poisson Zero Inflated Model\n",
    "- `ZeroInflatedNegativeBinomialP()` - Zero Inflated Generalized Negative Binomial Model\n",
    "- `ZeroInflatedGeneralizedPoisson()` - Zero Inflated Generalized Poisson Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rhum</th>\n",
       "      <th>rainfall_intensity</th>\n",
       "      <th>wind_speed_group</th>\n",
       "      <th>temp_r</th>\n",
       "      <th>holiday_False</th>\n",
       "      <th>holiday_True</th>\n",
       "      <th>peak_False</th>\n",
       "      <th>peak_True</th>\n",
       "      <th>timesofday_Afternoon</th>\n",
       "      <th>timesofday_Evening</th>\n",
       "      <th>timesofday_Morning</th>\n",
       "      <th>timesofday_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rhum  rainfall_intensity  wind_speed_group  temp_r  holiday_False  \\\n",
       "1444    96                   0                 0      -1              1   \n",
       "1652    63                   0                 2      12              1   \n",
       "\n",
       "      holiday_True  peak_False  peak_True  timesofday_Afternoon  \\\n",
       "1444             0           1          0                     0   \n",
       "1652             0           1          0                     0   \n",
       "\n",
       "      timesofday_Evening  timesofday_Morning  timesofday_Night  \n",
       "1444                   0                   0                 1  \n",
       "1652                   1                   0                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "# pipe_zip = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', sm.ZeroInflatedPoisson(y_train, X_with_constant, inflation='logit').fit(**params_zip))\n",
    "# ])\n",
    "\n",
    "# y_train_log = np.log1p(y_train)00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lpessini/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/statsmodels/base/model.py:547: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 2.148195\n",
      "         Iterations: 36\n",
      "         Function evaluations: 102\n",
      "         Gradient evaluations: 92\n",
      "                     ZeroInflatedNegativeBinomialP Regression Results                    \n",
      "=========================================================================================\n",
      "Dep. Variable:                             count   No. Observations:                 6132\n",
      "Model:             ZeroInflatedNegativeBinomialP   Df Residuals:                     6122\n",
      "Method:                                      MLE   Df Model:                            9\n",
      "Date:                           Thu, 28 Apr 2022   Pseudo R-squ.:                  0.1190\n",
      "Time:                                   20:13:33   Log-Likelihood:                -13173.\n",
      "converged:                                 False   LL-Null:                       -14952.\n",
      "Covariance Type:                             HC3   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "inflate_const           -3.0080      0.300    -10.040      0.000      -3.595      -2.421\n",
      "const                  -76.4878    121.292     -0.631      0.528    -314.217     161.241\n",
      "rhum                    -0.0153      0.001    -16.597      0.000      -0.017      -0.013\n",
      "rainfall_intensity      -0.1186      0.019     -6.407      0.000      -0.155      -0.082\n",
      "wind_speed_group        -0.0401      0.012     -3.312      0.001      -0.064      -0.016\n",
      "temp_r                   0.0245      0.002     12.396      0.000       0.021       0.028\n",
      "holiday_False         -389.6424    399.847     -0.974      0.330   -1173.328     394.043\n",
      "holiday_True          -389.7515    399.849     -0.975      0.330   -1173.441     393.938\n",
      "peak_False             468.2712    278.608      1.681      0.093     -77.791    1014.333\n",
      "peak_True              468.3474    278.608      1.681      0.093     -77.714    1014.409\n",
      "timesofday_Afternoon     0.5081      0.058      8.736      0.000       0.394       0.622\n",
      "timesofday_Evening       0.2795      0.061      4.609      0.000       0.161       0.398\n",
      "timesofday_Morning       0.4035      0.063      6.425      0.000       0.280       0.527\n",
      "timesofday_Night        -0.8303      0.066    -12.534      0.000      -0.960      -0.700\n",
      "alpha                    1.2229      0.041     30.000      0.000       1.143       1.303\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Zero-Inflated Negative Binomial model\n",
    "params_zip = {'maxiter': 50, \n",
    "             'method': 'nm'}\n",
    "\n",
    "X_with_constant = sm.add_constant(X_train)\n",
    "zip_mod = sm.ZeroInflatedNegativeBinomialP(y_train, X_with_constant,p=1, inflation='probit')\\\n",
    "    .fit(maxiter=150, method='minimize', cov_type='HC3', full_output=True, disp=True, skip_hessian=True)\n",
    "\n",
    "print(zip_mod.summary())\n",
    "# zinb_pred = zip_mod.predict(X_test)\n",
    "# zinb_rmse = np.sqrt(metrics.mean_squared_error(y_test, zinb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model: Zero Inflated Poisson\")\n",
    "# zip_mod = sm.ZeroInflatedPoisson(y_train, X_with_constant, inflation='logit').fit(method=\"nm\", maxiter=50)\n",
    "\n",
    "# zip_mean_pred = zip_mod.predict(X_test, exog_infl=np.ones((len(X_test), 1)))\n",
    "# zip_ppf_obs = stats.poisson.ppf(q=0.95, mu=zip_mean_pred)\n",
    "# zip_rmse = np.sqrt(metrics.mean_squared_error(y_test, zip_ppf_obs))\n",
    "\n",
    "# print(\"Model: Zero Inflated Neg. Binomial\")\n",
    "# zinb_mod = sm.ZeroInflatedNegativeBinomialP(y_train, X_with_constant).fit(method=\"nm\", maxiter=50)\n",
    "# zinb_pred = zip_mod.predict(X_test)\n",
    "# zinb_rmse = np.sqrt(metrics.mean_squared_error(y_test, zinb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cameron and Trivediâ€™s (CT) (1990) test\n",
    "\n",
    "It is based on the assumption that under the Poisson model ${(y-E[y])2 â€“E[y]}$ has zero mean:\n",
    "\n",
    "`H0`: (Poisson Model correct): $Var[yi] = E[yi]$\n",
    "<br>`HA`: $Var[yi] = E[yi] +Î± g(E[yi])$\n",
    "\n",
    "> CTâ€™s rule of thumb: If $Var[yi] / E[yi] > 2$ => **overdispersion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.47 => overdispersion found.\n"
     ]
    }
   ],
   "source": [
    "print(f'{round(hourly_data[\"count\"].var() / hourly_data[\"count\"].mean(), 2)} => overdispersion found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fdssd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/20m5cx314y19rmnyp58yqp5w0000gn/T/ipykernel_38324/416506833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfdssd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fdssd' is not defined"
     ]
    }
   ],
   "source": [
    "fdssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'holiday'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mcol_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'holiday'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/20m5cx314y19rmnyp58yqp5w0000gn/T/ipykernel_2752/3840731890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams_lightgbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m ])\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpipe_gbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#Plotting features importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[1;32m    389\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mtransformer_to_input_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A given column is not a column of the dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "# LightGBM model\n",
    "params_lightgbm = {'n_estimators': 5000,\n",
    "                   'objective': 'l1',\n",
    "                   'learning_rate': 0.01, \n",
    "                   'subsample': 0.7,\n",
    "                   'verbosity': -1,\n",
    "                   'feature_fraction': 0.5,\n",
    "                   'bagging_fraction': 0.5,\n",
    "                   'bagging_freq': 20,\n",
    "                   'importance_type': 'gain'\n",
    "                   }\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(**params_lightgbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "\n",
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_gbm['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolation problem \n",
    "\n",
    "When using a Random Forest Regressor, the predicted values are never outside the training set values for the target variable. If it is tasked with the problem of predicting for values not previously seen, it will always predict an average of the values seen previously. Obviously the average of a sample can not fall outside the highest and lowest values in the sample. \n",
    "\n",
    "The Random Forest Regressor is unable to discover trends that would enable it in extrapolating values that fall outside the training set. When faced with such a scenario, the regressor assumes that the prediction will fall close to the maximum value in the training set. \n",
    "\n",
    "\n",
    "### Potential solutions\n",
    "\n",
    "Ok, so how can you deal with this extrapolation problem?\n",
    "\n",
    "There are a couple of options:\n",
    "\n",
    "- Use a linear model such as SVM regression, Linear Regression, etc\n",
    "- Build a deep learning model because neural nets are able to extrapolate (they are basically stacked linear regression models on steroids)\n",
    "- Combine predictors using [stacking](https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html). For example, you can create a stacking regressor using a Linear model and a Random Forest Regressor. \n",
    "- Use modified versions of random forest\n",
    "\n",
    "One of such extensions is [Regression-Enhanced Random Forests](https://arxiv.org/pdf/1904.10416.pdf) (RERFs). The authors of this paper propose a technique borrowed from the strengths of penalized parametric regression to give better results in extrapolation problems.\n",
    "\n",
    "Specifically, there are two steps to the process:\n",
    "\n",
    "run Lasso before Random Forest, \n",
    "train a Random Forest on the residuals from Lasso. \n",
    "Since Random Forest is a fully nonparametric predictive algorithm, it may not efficiently incorporate known relationships between the response and the predictors. The response values are the observed values Y1, . . . , Yn  from the training data. RERFs are able to incorporate known relationships between the responses and the predictors which is another benefit of using Regression-Enhanced Random Forests for regression problems.\n",
    "\n",
    "Source: https://neptune.ai/blog/random-forest-regression-when-does-it-fail-and-why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/20m5cx314y19rmnyp58yqp5w0000gn/T/ipykernel_89368/1799765538.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams_rf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m ])\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpipe_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TUDublin/moby-bikes/conda-env/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='mae'))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00281782, 0.003025  , 0.01731016, 0.01510637, 0.01133228,\n",
       "       0.01307635, 0.01650186, 0.0168947 , 0.01746369, 0.00647813,\n",
       "       0.00608009, 0.01313422, 0.01699073, 0.00905364, 0.0131093 ,\n",
       "       0.01370769, 0.01460768, 0.01245663, 0.02010735, 0.01249554,\n",
       "       0.12089461, 0.02049032, 0.24891632, 0.22586378, 0.13208575])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf['model'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_rf['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Random Forest Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance = permutation_importance(pipe_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'importances_mean': array([0.08221604, 0.16911993, 0.00725372, 0.0023072 , 0.02915006,\n",
       "        0.00881072, 0.02786071, 0.04106132, 0.28433673, 0.00574815]),\n",
       " 'importances_std': array([0.00400861, 0.01925706, 0.00318497, 0.00053067, 0.0035655 ,\n",
       "        0.0013148 , 0.00367139, 0.00492719, 0.00462203, 0.00179732]),\n",
       " 'importances': array([[0.08166053, 0.08303394, 0.08914898, 0.08026391, 0.07697286],\n",
       "        [0.18570406, 0.17648185, 0.18659132, 0.13495779, 0.16186463],\n",
       "        [0.00847793, 0.00534775, 0.01099289, 0.00205531, 0.00939473],\n",
       "        [0.00240963, 0.00213196, 0.00150338, 0.00233533, 0.0031557 ],\n",
       "        [0.03195476, 0.03457041, 0.02688944, 0.02486019, 0.02747552],\n",
       "        [0.00959177, 0.00997252, 0.00730609, 0.00712128, 0.01006196],\n",
       "        [0.03093017, 0.02695938, 0.02665653, 0.03263452, 0.02212293],\n",
       "        [0.04640973, 0.03336568, 0.04611459, 0.04118491, 0.03823169],\n",
       "        [0.28658365, 0.29007879, 0.2829703 , 0.27628206, 0.28576885],\n",
       "        [0.00508658, 0.00811529, 0.0058759 , 0.00278039, 0.0068826 ]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 9, 2, 5, 6, 4, 7, 0, 1, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "sorted_idx\n",
    "# plt.barh(feature_imp[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='mae'))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_gbm['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Random Forest Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5, \n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "# y_train_pred = pipe_rf.predict(X_train)\n",
    "# y_test_pred = pipe_rf.predict(X_test)\n",
    "\n",
    "# print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', SVR(kernel='poly',gamma='scale',C=100))\n",
    "])\n",
    "pipe_svr.fit(X_train, y_train)\n",
    "y_train_pred = pipe_svr.predict(X_train)\n",
    "y_test_pred = pipe_svr.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define the model cross-validation configuration\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# evaluate the pipeline using cross validation and calculate MAE\n",
    "scores = cross_val_score(pipe_svr, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# convert MAE scores to positive values\n",
    "scores = absolute(scores)\n",
    "# summarize the model performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "y_test_pred = pipe_svr.predict(X_test)\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = pd.DataFrame()\n",
    "predicted_values['real'] = y_test\n",
    "predicted_values['predicted'] = y_test_pred\n",
    "\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM model\n",
    "params_gbm = {'n_estimators': 150, \n",
    "              'max_depth': 5, \n",
    "              'random_state': 0, \n",
    "              'min_samples_leaf' : 10, \n",
    "              'learning_rate': 0.01, \n",
    "              'subsample': 0.7, \n",
    "              'loss': 'ls'}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(**params_gbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "y_train_pred = pipe_gbm.predict(X_train)\n",
    "y_test_pred = pipe_gbm.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model\n",
    "params_lightgbm = {'n_estimators': 1000, \n",
    "                   'max_depth': 15, \n",
    "                   'random_state': 0, \n",
    "                   'learning_rate': 0.01, \n",
    "                   'subsample': 0.7,\n",
    "                   'num_leaves': 30,\n",
    "                   'metric': 'rmse',\n",
    "                   'n_jobs': 2\n",
    "                   }\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(**params_lightgbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "y_train_pred = pipe_gbm.predict(X_train)\n",
    "y_test_pred = pipe_gbm.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=2022)\n",
    "\n",
    "for n_fold, (train_index, test_index) in enumerate(cv.split(X_train, y_train)):\n",
    "    print('#'*40, f'Fold {n_fold+1} out of {cv.n_splits}', '#'*40)\n",
    "    \n",
    "    # X_train, y_train = X[train_index], y[train_index] # Train data\n",
    "    # X_val, y_val = X[test_index], y[test_index] # Valid data\n",
    "    \n",
    "    # pipe_gbm.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    #           verbose=250, early_stopping_rounds=50)\n",
    "    \n",
    "    # preds_lgb[test_index] += pipe_gbm.predict(X_val, raw_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost model\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_catboost = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', CatBoostRegressor(verbose=1, n_estimators=100))\n",
    "])\n",
    "pipe_catboost.fit(X_train, y_train)\n",
    "y_train_pred = pipe_catboost.predict(X_train)\n",
    "y_test_pred = pipe_catboost.predict(X_test)\n",
    "\n",
    "print('\\n')\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Mark\" src=\"./img/GitHub-Mark-64px.png\" style=\"height: 32px; padding-right: 15px\" alt=\"GitHub Mark\" align=\"left\"> [GitHub repository](https://github.com/pessini/moby-bikes) <br>Author: Leandro Pessini"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c82cf216bcd6695c751af4e033b89e10a78cc5d50e2943f0ed5dd08b475eddb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
