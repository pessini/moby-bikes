{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Octocat\" src='./img/Octocat.jpg' style='height: 60px; padding-right: 15px' alt=\"Octocat\" align=\"left\"> This notebook is part of a GitHub repository: https://github.com/pessini/moby-bikes \n",
    "<br>MIT Licensed\n",
    "<br>Author: Leandro Pessini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Models</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Table of Contents:</p>\n",
    "* [1. Datasets](#1)\n",
    "  * [1.1 Rentals Data - Moby Bikes](#1.1)\n",
    "  * [1.2 Weather Data - Met Éireann](#1.2)\n",
    "* [2. Preprocessing & Feature Engineering](#2)\n",
    "  * [2.1 Target variable distribution](#2.1)\n",
    "  * [2.2 Missing values](#2.2)\n",
    "  * [2.3 Exploratory Analysis](#2.3)\n",
    "  * [2.4 Features Importance](#2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models & Evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import bambi as bmb\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats as stats\n",
    "import statsmodels.distributions.discrete as distr\n",
    "\n",
    "# Boost models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cat\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Hyperparameter optimization\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Leandro Pessini\n",
      "\n",
      "Last updated: Fri Apr 29 2022\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.6\n",
      "IPython version      : 7.25.0\n",
      "\n",
      "matplotlib : 3.4.2\n",
      "lightgbm   : 3.2.1\n",
      "catboost   : 0.26.1\n",
      "numpy      : 1.21.1\n",
      "sklearn    : 1.0.2\n",
      "bambi      : 0.7.1\n",
      "seaborn    : 0.11.1\n",
      "pandas     : 1.3.0\n",
      "xgboost    : 1.4.0\n",
      "sys        : 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:36:15) \n",
      "[Clang 11.1.0 ]\n",
      "statsmodels: 0.12.2\n",
      "\n",
      "Watermark: 2.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Leandro Pessini\" -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8760, 24), (6966, 24))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data = pd.read_csv('../data/processed/hourly_data.csv')\n",
    "hourly_rentals = pd.read_csv('../data/processed/hourly_rentals.csv')\n",
    "hourly_data.shape, hourly_rentals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>rhum</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>holiday</th>\n",
       "      <th>...</th>\n",
       "      <th>peak</th>\n",
       "      <th>timesofday</th>\n",
       "      <th>rainfall_intensity</th>\n",
       "      <th>wind_bft</th>\n",
       "      <th>wind_speed_group</th>\n",
       "      <th>temp_r</th>\n",
       "      <th>temp_kbin</th>\n",
       "      <th>temp_kbin_quantile</th>\n",
       "      <th>temp_kbin_kmeans</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>no rain</td>\n",
       "      <td>2</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>no rain</td>\n",
       "      <td>2</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rain  temp  rhum  wdsp        date  hour  day  month  year  holiday  ...  \\\n",
       "0   0.0   0.1    98     4  2021-03-01     0    1      3  2021    False  ...   \n",
       "1   0.0  -1.1    98     3  2021-03-01     1    1      3  2021    False  ...   \n",
       "\n",
       "    peak timesofday  rainfall_intensity wind_bft     wind_speed_group temp_r  \\\n",
       "0  False      Night             no rain        2  Calm / Light Breeze      0   \n",
       "1  False      Night             no rain        2  Calm / Light Breeze     -1   \n",
       "\n",
       "  temp_kbin  temp_kbin_quantile temp_kbin_kmeans  count  \n",
       "0       1.0                 0.0              0.0      0  \n",
       "1       1.0                 0.0              0.0      0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Example of dynamic table with evalution metrics: https://www.kirenz.com/post/2021-12-06-regression-splines-in-python/regression-splines-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# transform the temperature with KBinsDiscretizer\n",
    "enc = KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy='kmeans')\n",
    "hourly_data['humidity_kbin'] = enc.fit_transform(hourly_data['rhum'].array.reshape(-1,1))\n",
    "hourly_rentals['humidity_kbin'] = enc.fit_transform(hourly_rentals['rhum'].array.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4876, 11), (2090, 11))"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hourly_rentals.copy()\n",
    "# df = hourly_rentals.copy()\n",
    "df = df.astype({'holiday': 'category',\n",
    "                'working_day': 'category',\n",
    "                'peak': 'category',\n",
    "                'season': 'category',\n",
    "                'dayofweek': 'category',\n",
    "                'timesofday': 'category',\n",
    "                'rainfall_intensity': 'category',\n",
    "                'wind_bft': 'category',\n",
    "                'wind_speed_group': 'category'})\n",
    "\n",
    "df['humidity_norm'] = df['rhum']/100\n",
    "# predictors = ['temp_r','wind_speed_group','humidity_norm','rainfall_intensity','holiday','season','dayofweek','working_day','peak','timesofday']\n",
    "predictors = ['temp_kbin_quantile','wind_speed_group','rainfall_intensity','holiday','peak','timesofday']\n",
    "\n",
    "# OrdinalEnconder\n",
    "enc_rain = OrdinalEncoder(dtype=np.int64, \\\n",
    "    categories=[['no rain', 'drizzle', 'light rain', 'moderate rain', 'heavy rain']])\n",
    "df['rainfall_intensity'] = enc_rain.fit_transform(df[['rainfall_intensity']])\n",
    "\n",
    "enc_wind = OrdinalEncoder(dtype=np.int64, \\\n",
    "    categories=[['Calm / Light Breeze', 'Breeze', 'Moderate Breeze', 'Strong Breeze / Near Gale','Gale / Storm']])\n",
    "df['wind_speed_group'] = enc_wind.fit_transform(df[['wind_speed_group']])\n",
    "\n",
    "X = df[[c for c in df.columns if c in predictors]]\n",
    "y = df.pop('count')\n",
    "\n",
    "num_vars = [n for n in df.select_dtypes(include=['number']).columns if n in predictors] # list comprehension to select only predictors features\n",
    "cat_vars = [c for c in df.select_dtypes(include=['category']).columns if c in predictors]\n",
    "\n",
    "dummies = pd.get_dummies(X[cat_vars], drop_first=False)\n",
    "X = pd.concat([X[num_vars], dummies],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rainfall_intensity</th>\n",
       "      <th>wind_speed_group</th>\n",
       "      <th>temp_kbin_quantile</th>\n",
       "      <th>holiday_True</th>\n",
       "      <th>peak_True</th>\n",
       "      <th>timesofday_Evening</th>\n",
       "      <th>timesofday_Morning</th>\n",
       "      <th>timesofday_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rainfall_intensity  wind_speed_group  temp_kbin_quantile  holiday_True  \\\n",
       "5768                   0                 2                 3.0             0   \n",
       "2995                   0                 2                 7.0             0   \n",
       "\n",
       "      peak_True  timesofday_Evening  timesofday_Morning  timesofday_Night  \n",
       "5768          0                   0                   0                 0  \n",
       "2995          0                   1                   0                 0  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2.338111\n",
      "         Iterations: 844\n",
      "         Function evaluations: 1177\n"
     ]
    }
   ],
   "source": [
    "# Zero-Inflated Negative Binomial model\n",
    "# X_with_constant = sm.add_constant(X_train)\n",
    "# model_zinb = sm.NegativeBinomialP(endog=y_train, exog=X_train, exog_infl=X_train, inflation='logit')\n",
    "# res_zinb = model_zinb.fit(maxiter=150, method='minimize', cov_type='HC3', disp=True)\n",
    "\n",
    "# method => ‘newton’ for Newton-Raphson, ‘nm’ for Nelder-Mead, ‘bfgs’ for Broyden-Fletcher-Goldfarb-Shanno (BFGS)\n",
    "# ‘lbfgs’ for limited-memory BFGS with optional box constraints, ‘powell’ for modified Powell’s method\n",
    "# ‘cg’ for conjugate gradient, ‘ncg’ for Newton-conjugate gradient\n",
    "# ‘basinhopping’ for global basin-hopping solver, ‘minimize’ for generic wrapper of scipy minimize (BFGS by default)\n",
    "model_zinb = sm.NegativeBinomialP(endog=y_train, exog=X_train)\n",
    "res_zinb = model_zinb.fit(maxiter=5000, method='nm', cov_type='HC3', disp=True, retall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     NegativeBinomialP Regression Results                     \n",
      "==============================================================================\n",
      "Dep. Variable:                  count   No. Observations:                 4876\n",
      "Model:              NegativeBinomialP   Df Residuals:                     4867\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Fri, 29 Apr 2022   Pseudo R-squ.:                 0.06142\n",
      "Time:                        22:46:13   Log-Likelihood:                -11401.\n",
      "converged:                       True   LL-Null:                       -12147.\n",
      "Covariance Type:                  HC3   LLR p-value:                     0.000\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "rainfall_intensity      -0.1579      1.625     -0.097      0.923      -3.343       3.027\n",
      "wind_speed_group        -0.0176      0.044     -0.399      0.690      -0.104       0.069\n",
      "temp_kbin_quantile       0.0499      0.019      2.650      0.008       0.013       0.087\n",
      "holiday_False            0.5110   9.12e+13    5.6e-15      1.000   -1.79e+14    1.79e+14\n",
      "holiday_True             0.5642   9.12e+13   6.18e-15      1.000   -1.79e+14    1.79e+14\n",
      "peak_False               0.5048   9.12e+13   5.53e-15      1.000   -1.79e+14    1.79e+14\n",
      "peak_True                0.5248   9.12e+13   5.75e-15      1.000   -1.79e+14    1.79e+14\n",
      "timesofday_Afternoon     0.5626    8.5e+05   6.62e-07      1.000   -1.67e+06    1.67e+06\n",
      "timesofday_Evening       0.2219   7.64e+05    2.9e-07      1.000    -1.5e+06     1.5e+06\n",
      "timesofday_Morning       0.4000   1.01e+06   3.96e-07      1.000   -1.98e+06    1.98e+06\n",
      "timesofday_Night        -0.3212   7.54e+05  -4.26e-07      1.000   -1.48e+06    1.48e+06\n",
      "alpha                    0.1621      0.007     22.026      0.000       0.148       0.177\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(res_zinb.summary())\n",
    "# zinb_pred = zip_mod.predict(X_test)\n",
    "# zinb_rmse = np.sqrt(metrics.mean_squared_error(y_test, zinb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZINB RMSE=140.71247279470288\n"
     ]
    }
   ],
   "source": [
    "zinb_predictions = res_zinb.predict(X_test)\n",
    "predicted_counts=np.round(zinb_predictions)\n",
    "actual_counts = y_test\n",
    "print(f'ZINB RMSE={str(np.sqrt(np.sum(np.power(np.subtract(predicted_counts,actual_counts),2))))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22821.26074166484"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_zinb.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <th>timesofday</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">False</th>\n",
       "      <th>Afternoon</th>\n",
       "      <td>6.363636</td>\n",
       "      <td>13.108490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evening</th>\n",
       "      <td>4.330896</td>\n",
       "      <td>8.378856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morning</th>\n",
       "      <td>5.166267</td>\n",
       "      <td>11.813180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night</th>\n",
       "      <td>2.396936</td>\n",
       "      <td>3.573343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">True</th>\n",
       "      <th>Afternoon</th>\n",
       "      <td>7.619048</td>\n",
       "      <td>27.607433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Evening</th>\n",
       "      <td>4.156250</td>\n",
       "      <td>8.523185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morning</th>\n",
       "      <td>5.258065</td>\n",
       "      <td>18.997849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night</th>\n",
       "      <td>1.678571</td>\n",
       "      <td>1.263228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean        var\n",
       "holiday timesofday                     \n",
       "False   Afternoon   6.363636  13.108490\n",
       "        Evening     4.330896   8.378856\n",
       "        Morning     5.166267  11.813180\n",
       "        Night       2.396936   3.573343\n",
       "True    Afternoon   7.619048  27.607433\n",
       "        Evening     4.156250   8.523185\n",
       "        Morning     5.258065  18.997849\n",
       "        Night       1.678571   1.263228"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_rentals.groupby([\"holiday\", \"timesofday\"])[\"count\"].agg([\"mean\", \"var\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up(x):\n",
    "    '''\n",
    "    Helper function to round away from zero\n",
    "    '''\n",
    "    from math import copysign\n",
    "    return int(x + copysign(0.5, x))\n",
    "\n",
    "d = {'Actual': y_test, 'Predicted': zinb_predictions}\n",
    "df_pred = pd.DataFrame(data=d)\n",
    "df_pred['Predicted'] = df_pred['Predicted'].apply(round_up)\n",
    "\n",
    "# df_pred = df_pred[df_pred['Actual'] == 0]\n",
    "df_pred.to_csv('actualvspredicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2090.000000\n",
       "mean        4.651675\n",
       "std         1.646096\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         5.000000\n",
       "75%         6.000000\n",
       "max         8.000000\n",
       "Name: Predicted, dtype: float64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred['Predicted'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Discrete Dependent Variable¶\n",
    "\n",
    "\n",
    "Regression models for limited and qualitative dependent variables. Count (Poisson, NegativeBinomial) data.\n",
    "\n",
    "- Poisson / Zero-Inflated Poisson (ZIP)\n",
    "- Negative Binomial / Zero-Inflated Negative Binomial (ZINB)\n",
    "\n",
    "### statsmodels library\n",
    "\n",
    "- `Poisson()` - Poisson Model\n",
    "- `NegativeBinomial()` - Negative Binomial Model\n",
    "- `NegativeBinomialP()` - Generalized Negative Binomial (NB-P) Model\n",
    "- `GeneralizedPoisson()` - Generalized Poisson Model\n",
    "- `ZeroInflatedPoisson()` - Poisson Zero Inflated Model\n",
    "- `ZeroInflatedNegativeBinomialP()` - Zero Inflated Generalized Negative Binomial Model\n",
    "- `ZeroInflatedGeneralizedPoisson()` - Zero Inflated Generalized Poisson Model\n",
    "\n",
    "\n",
    "### Abbreviations\n",
    "- ZI: Zero-inflated; \n",
    "- ZIP: Zero-inflated poisson; \n",
    "- NB: Negative binomial; \n",
    "- ZINB: Zero-inflated negative binomial; \n",
    "- HNB: Hurdle negative binomial; \n",
    "- PMF: Probability mass function; \n",
    "- CDF: Cumulative distributions function; \n",
    "- RQR: Randomized quantile residuals; \n",
    "- SW: Shaprio-Wilk; \n",
    "- AIC: Akaike information criterion\n",
    "\n",
    "\n",
    "\n",
    "### Goodness of fit statistics\n",
    "- Pearson Chi-Square test\n",
    "- Log-Likelihood Ratio test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Model: Zero Inflated Poisson\")\n",
    "# zip_mod = sm.ZeroInflatedPoisson(y_train, X_with_constant, inflation='logit').fit(method=\"nm\", maxiter=50)\n",
    "\n",
    "# zip_mean_pred = zip_mod.predict(X_test, exog_infl=np.ones((len(X_test), 1)))\n",
    "# zip_ppf_obs = stats.poisson.ppf(q=0.95, mu=zip_mean_pred)\n",
    "# zip_rmse = np.sqrt(metrics.mean_squared_error(y_test, zip_ppf_obs))\n",
    "\n",
    "# print(\"Model: Zero Inflated Neg. Binomial\")\n",
    "# zinb_mod = sm.ZeroInflatedNegativeBinomialP(y_train, X_with_constant).fit(method=\"nm\", maxiter=50)\n",
    "# zinb_pred = zip_mod.predict(X_test)\n",
    "# zinb_rmse = np.sqrt(metrics.mean_squared_error(y_test, zinb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp_kbin_quantile',\n",
       " 'wind_speed_group',\n",
       " 'rainfall_intensity',\n",
       " 'holiday',\n",
       " 'peak',\n",
       " 'timesofday']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [count_alpha, holiday:timesofday, timesofday, holiday, rainfall_intensity, wind_speed_group, temp_kbin_quantile, Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4000/4000 00:49<00:00 Sampling 2 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 1_000 draw iterations (2_000 + 2_000 draws total) took 61 seconds.\n"
     ]
    }
   ],
   "source": [
    "fml = \"count ~ temp_kbin_quantile + wind_speed_group + rainfall_intensity + holiday + timesofday + holiday:timesofday\"\n",
    "\n",
    "model = bmb.Model(fml, hourly_rentals, family=\"negativebinomial\")\n",
    "trace = model.fit(draws=1000, tune=1000, cores=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>1.329</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.411</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2497.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp_kbin_quantile</th>\n",
       "      <td>0.045</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4255.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed_group[Calm / Light Breeze]</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2933.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed_group[Gale / Storm]</th>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.564</td>\n",
       "      <td>-1.474</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.011</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>1578.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed_group[Moderate Breeze]</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3108.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind_speed_group[Strong Breeze / Near Gale]</th>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfall_intensity[heavy rain]</th>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfall_intensity[light rain]</th>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.187</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3352.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfall_intensity[moderate rain]</th>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.061</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfall_intensity[no rain]</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>0.193</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2065.0</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timesofday[Evening]</th>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.377</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timesofday[Morning]</th>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timesofday[Night]</th>\n",
       "      <td>-0.884</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday:timesofday[Evening]</th>\n",
       "      <td>-0.216</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday:timesofday[Morning]</th>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.137</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2383.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday:timesofday[Night]</th>\n",
       "      <td>-0.539</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.915</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2796.0</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_alpha</th>\n",
       "      <td>6.178</td>\n",
       "      <td>0.243</td>\n",
       "      <td>5.697</td>\n",
       "      <td>6.597</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3447.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              mean     sd  hdi_3%  hdi_97%  \\\n",
       "Intercept                                    1.329  0.044   1.246    1.411   \n",
       "temp_kbin_quantile                           0.045  0.003   0.040    0.051   \n",
       "wind_speed_group[Calm / Light Breeze]        0.018  0.018  -0.015    0.053   \n",
       "wind_speed_group[Gale / Storm]              -0.404  0.564  -1.474    0.609   \n",
       "wind_speed_group[Moderate Breeze]            0.005  0.019  -0.029    0.042   \n",
       "wind_speed_group[Strong Breeze / Near Gale] -0.171  0.066  -0.297   -0.049   \n",
       "rainfall_intensity[heavy rain]              -0.024  0.235  -0.469    0.398   \n",
       "rainfall_intensity[light rain]              -0.029  0.087  -0.187    0.136   \n",
       "rainfall_intensity[moderate rain]           -0.148  0.061  -0.259   -0.032   \n",
       "rainfall_intensity[no rain]                  0.272  0.037   0.206    0.345   \n",
       "holiday                                      0.193  0.088   0.022    0.351   \n",
       "timesofday[Evening]                         -0.338  0.020  -0.377   -0.302   \n",
       "timesofday[Morning]                         -0.162  0.019  -0.198   -0.126   \n",
       "timesofday[Night]                           -0.884  0.025  -0.930   -0.838   \n",
       "holiday:timesofday[Evening]                 -0.216  0.138  -0.481    0.041   \n",
       "holiday:timesofday[Morning]                 -0.125  0.137  -0.392    0.115   \n",
       "holiday:timesofday[Night]                   -0.539  0.188  -0.915   -0.218   \n",
       "count_alpha                                  6.178  0.243   5.697    6.597   \n",
       "\n",
       "                                             mcse_mean  mcse_sd  ess_bulk  \\\n",
       "Intercept                                        0.001    0.001    2497.0   \n",
       "temp_kbin_quantile                               0.000    0.000    4255.0   \n",
       "wind_speed_group[Calm / Light Breeze]            0.000    0.000    2933.0   \n",
       "wind_speed_group[Gale / Storm]                   0.009    0.011    3968.0   \n",
       "wind_speed_group[Moderate Breeze]                0.000    0.000    3108.0   \n",
       "wind_speed_group[Strong Breeze / Near Gale]      0.001    0.001    4343.0   \n",
       "rainfall_intensity[heavy rain]                   0.004    0.005    3785.0   \n",
       "rainfall_intensity[light rain]                   0.002    0.002    3352.0   \n",
       "rainfall_intensity[moderate rain]                0.001    0.001    2748.0   \n",
       "rainfall_intensity[no rain]                      0.001    0.001    2300.0   \n",
       "holiday                                          0.002    0.002    2065.0   \n",
       "timesofday[Evening]                              0.000    0.000    2297.0   \n",
       "timesofday[Morning]                              0.000    0.000    2703.0   \n",
       "timesofday[Night]                                0.000    0.000    2640.0   \n",
       "holiday:timesofday[Evening]                      0.003    0.002    2272.0   \n",
       "holiday:timesofday[Morning]                      0.003    0.002    2383.0   \n",
       "holiday:timesofday[Night]                        0.004    0.003    2796.0   \n",
       "count_alpha                                      0.004    0.003    3447.0   \n",
       "\n",
       "                                             ess_tail  r_hat  \n",
       "Intercept                                      1395.0    1.0  \n",
       "temp_kbin_quantile                             1775.0    1.0  \n",
       "wind_speed_group[Calm / Light Breeze]          1415.0    1.0  \n",
       "wind_speed_group[Gale / Storm]                 1578.0    1.0  \n",
       "wind_speed_group[Moderate Breeze]              1689.0    1.0  \n",
       "wind_speed_group[Strong Breeze / Near Gale]    1728.0    1.0  \n",
       "rainfall_intensity[heavy rain]                 1574.0    1.0  \n",
       "rainfall_intensity[light rain]                 1456.0    1.0  \n",
       "rainfall_intensity[moderate rain]              1556.0    1.0  \n",
       "rainfall_intensity[no rain]                    1332.0    1.0  \n",
       "holiday                                        1335.0    1.0  \n",
       "timesofday[Evening]                            1925.0    1.0  \n",
       "timesofday[Morning]                            1698.0    1.0  \n",
       "timesofday[Night]                              1783.0    1.0  \n",
       "holiday:timesofday[Evening]                    1717.0    1.0  \n",
       "holiday:timesofday[Morning]                    1440.0    1.0  \n",
       "holiday:timesofday[Night]                      1436.0    1.0  \n",
       "count_alpha                                    1474.0    1.0  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical pipeline\n",
    "cat_pipe = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "# Define numerical pipeline\n",
    "num_pipe = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    # ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "ord_pipe = Pipeline([\n",
    "    ('ordinal_enconder', OrdinalEncoder(dtype=np.int64, categories=[['no rain', \n",
    "                                                                     'drizzle', \n",
    "                                                                     'light rain', \n",
    "                                                                     'moderate rain', \n",
    "                                                                     'heavy rain']]))\n",
    "])\n",
    "\n",
    "# Combine categorical and numerical pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipe, cat_vars),\n",
    "    ('ordinal_enconder', ord_pipe, ord_var),\n",
    "    ('num', num_pipe, num_vars)\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model\n",
    "params_lightgbm = {'n_estimators': 5000,\n",
    "                   'objective': 'l1',\n",
    "                   'learning_rate': 0.01, \n",
    "                   'subsample': 0.7,\n",
    "                   'verbosity': -1,\n",
    "                   'feature_fraction': 0.5,\n",
    "                   'bagging_fraction': 0.5,\n",
    "                   'bagging_freq': 20,\n",
    "                   'importance_type': 'gain'\n",
    "                   }\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(**params_lightgbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "\n",
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_gbm['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolation problem \n",
    "\n",
    "When using a Random Forest Regressor, the predicted values are never outside the training set values for the target variable. If it is tasked with the problem of predicting for values not previously seen, it will always predict an average of the values seen previously. Obviously the average of a sample can not fall outside the highest and lowest values in the sample. \n",
    "\n",
    "The Random Forest Regressor is unable to discover trends that would enable it in extrapolating values that fall outside the training set. When faced with such a scenario, the regressor assumes that the prediction will fall close to the maximum value in the training set. \n",
    "\n",
    "\n",
    "### Potential solutions\n",
    "\n",
    "Ok, so how can you deal with this extrapolation problem?\n",
    "\n",
    "There are a couple of options:\n",
    "\n",
    "- Use a linear model such as SVM regression, Linear Regression, etc\n",
    "- Build a deep learning model because neural nets are able to extrapolate (they are basically stacked linear regression models on steroids)\n",
    "- Combine predictors using [stacking](https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html). For example, you can create a stacking regressor using a Linear model and a Random Forest Regressor. \n",
    "- Use modified versions of random forest\n",
    "\n",
    "One of such extensions is [Regression-Enhanced Random Forests](https://arxiv.org/pdf/1904.10416.pdf) (RERFs). The authors of this paper propose a technique borrowed from the strengths of penalized parametric regression to give better results in extrapolation problems.\n",
    "\n",
    "Specifically, there are two steps to the process:\n",
    "\n",
    "run Lasso before Random Forest, \n",
    "train a Random Forest on the residuals from Lasso. \n",
    "Since Random Forest is a fully nonparametric predictive algorithm, it may not efficiently incorporate known relationships between the response and the predictors. The response values are the observed values Y1, . . . , Yn  from the training data. RERFs are able to incorporate known relationships between the responses and the predictors which is another benefit of using Regression-Enhanced Random Forests for regression problems.\n",
    "\n",
    "Source: https://neptune.ai/blog/random-forest-regression-when-does-it-fail-and-why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='mae'))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf['model'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_rf['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Random Forest Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance = permutation_importance(pipe_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "sorted_idx\n",
    "# plt.barh(feature_imp[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='mae'))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_gbm['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Random Forest Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5, \n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "# y_train_pred = pipe_rf.predict(X_train)\n",
    "# y_test_pred = pipe_rf.predict(X_test)\n",
    "\n",
    "# print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', SVR(kernel='poly',gamma='scale',C=100))\n",
    "])\n",
    "pipe_svr.fit(X_train, y_train)\n",
    "y_train_pred = pipe_svr.predict(X_train)\n",
    "y_test_pred = pipe_svr.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define the model cross-validation configuration\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# evaluate the pipeline using cross validation and calculate MAE\n",
    "scores = cross_val_score(pipe_svr, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# convert MAE scores to positive values\n",
    "scores = absolute(scores)\n",
    "# summarize the model performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "y_test_pred = pipe_svr.predict(X_test)\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = pd.DataFrame()\n",
    "predicted_values['real'] = y_test\n",
    "predicted_values['predicted'] = y_test_pred\n",
    "\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM model\n",
    "params_gbm = {'n_estimators': 150, \n",
    "              'max_depth': 5, \n",
    "              'random_state': 0, \n",
    "              'min_samples_leaf' : 10, \n",
    "              'learning_rate': 0.01, \n",
    "              'subsample': 0.7, \n",
    "              'loss': 'ls'}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(**params_gbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "y_train_pred = pipe_gbm.predict(X_train)\n",
    "y_test_pred = pipe_gbm.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model\n",
    "params_lightgbm = {'n_estimators': 1000, \n",
    "                   'max_depth': 15, \n",
    "                   'random_state': 0, \n",
    "                   'learning_rate': 0.01, \n",
    "                   'subsample': 0.7,\n",
    "                   'num_leaves': 30,\n",
    "                   'metric': 'rmse',\n",
    "                   'n_jobs': 2\n",
    "                   }\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(**params_lightgbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "y_train_pred = pipe_gbm.predict(X_train)\n",
    "y_test_pred = pipe_gbm.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=2022)\n",
    "\n",
    "for n_fold, (train_index, test_index) in enumerate(cv.split(X_train, y_train)):\n",
    "    print('#'*40, f'Fold {n_fold+1} out of {cv.n_splits}', '#'*40)\n",
    "    \n",
    "    # X_train, y_train = X[train_index], y[train_index] # Train data\n",
    "    # X_val, y_val = X[test_index], y[test_index] # Valid data\n",
    "    \n",
    "    # pipe_gbm.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    #           verbose=250, early_stopping_rounds=50)\n",
    "    \n",
    "    # preds_lgb[test_index] += pipe_gbm.predict(X_val, raw_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost model\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_catboost = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', CatBoostRegressor(verbose=1, n_estimators=100))\n",
    "])\n",
    "pipe_catboost.fit(X_train, y_train)\n",
    "y_train_pred = pipe_catboost.predict(X_train)\n",
    "y_test_pred = pipe_catboost.predict(X_test)\n",
    "\n",
    "print('\\n')\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Mark\" src=\"./img/GitHub-Mark-64px.png\" style=\"height: 32px; padding-right: 15px\" alt=\"GitHub Mark\" align=\"left\"> [GitHub repository](https://github.com/pessini/moby-bikes) <br>Author: Leandro Pessini"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c82cf216bcd6695c751af4e033b89e10a78cc5d50e2943f0ed5dd08b475eddb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
