{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Octocat\" src='./img/Octocat.jpg' style='height: 60px; padding-right: 15px' alt=\"Octocat\" align=\"left\"> This notebook is part of a GitHub repository: https://github.com/pessini/moby-bikes \n",
    "<br>MIT Licensed\n",
    "<br>Author: Leandro Pessini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models & Evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats as stats\n",
    "\n",
    "# Boost models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cat\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Hyperparameter optimization\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Custom objects\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "import experiment_tracker as et\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/processed/df_train.csv')\n",
    "df_test = pd.read_csv('../data/processed/df_test.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new object to keep track of the experiments\n",
    "experiment_tracker = et.ExperimentTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.copy()\n",
    "X = df.drop(['count'], axis=1)\n",
    "y = df.pop('count')\n",
    "all_columns = list(X.columns)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_test.copy()\n",
    "X_test = test_df.drop(['count'], axis=1)\n",
    "y_test = test_df.pop('count')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_dummy = et.Idea(idea='Dummy Regressor', potential_outcome='To use as a baseline model, expected to perform badly.')\n",
    "experiment_tracker.new_idea(idea_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_score(model, predictors, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val):\n",
    "    \n",
    "    X_train = X_train[[c for c in X_train.columns if c in predictors]]\n",
    "    X_val = X_val[[c for c in X_val.columns if c in predictors]]\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and validation set\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Calculate the RSME and MAE\n",
    "    train_rsme = metrics.mean_squared_error(y_train, y_pred_train, squared=False) \n",
    "    # If squared = True returns MSE value, if False returns RMSE value.\n",
    "    val_rsme = metrics.mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "    train_mae = metrics.mean_absolute_error(y_train, y_pred_train)\n",
    "    val_mae = metrics.mean_absolute_error(y_val, y_pred_val)\n",
    "    \n",
    "    return train_rsme, val_rsme, train_mae, val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_to_Experiment() -> list:\n",
    "    rsme = et.Score('RSME', '{:.2f}'.format(train_rsme), '{:.2f}'.format(val_rsme))\n",
    "    mae = et.Score('MAE', '{:.2f}'.format(train_mae), '{:.2f}'.format(val_mae))\n",
    "    return [rsme, mae]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "predictors = ['temp','rhum','wdsp','rain']\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(dummy_regr, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dummy_regr = et.Experiment('Dummy Regressor', predictors=predictors, hyperparameters=dummy_regr.get_params(), \n",
    "                               score=get_metrics_to_Experiment(), notes='Baseline Model for comparison')\n",
    "experiment_tracker.add_experiment(exp_dummy_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_linear = et.Idea(idea='Linear Regression', potential_outcome='Expected to perform bad as we have many outliers and a count as target variable')\n",
    "experiment_tracker.new_idea(idea_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "predictors = ['temp','rhum','wdsp','rain']\n",
    "lin_reg = LinearRegression()\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(lin_reg, predictors)\n",
    "exp_lin_regr = et.Experiment('Linear Regression', predictors=predictors, hyperparameters='', \n",
    "                               score=get_metrics_to_Experiment(), notes='Linear Regression')\n",
    "experiment_tracker.add_experiment(exp_lin_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_tracker.update_idea(idea_linear, learnings='As expected the performance is not good as we have a lot of outliers and a count as target variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_random_forest = et.Idea(idea='Random Forest', potential_outcome='Expected to perform better than the Linear Regression')\n",
    "experiment_tracker.new_idea(idea_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "predictors = ['temp','rhum','wdsp','rain']\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(rf, predictors)\n",
    "exp_rf_regr = et.Experiment('Random Forest', predictors=predictors, hyperparameters=rf.get_params(), \n",
    "                               score=get_metrics_to_Experiment(), notes='')\n",
    "experiment_tracker.add_experiment(exp_rf_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update ideas with learnings\n",
    "learnings = \\\n",
    "\"\"\"Random Forest with just a few hyperparameters performed just a little better than linear regression (validations score).\n",
    "It seems to be overfitting as we see validation scores much higher than training scores. It's a sign that tuning hyperparameters is needed.\"\"\"\n",
    "experiment_tracker.update_idea(idea_random_forest, learnings=str.strip(learnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "def preprocessor(predictors: list) -> ColumnTransformer:\n",
    "    # Setting remainder='passthrough' will mean that all columns not specified in the list of “transformers” \n",
    "    #   will be passed through without transformation, instead of being dropped\n",
    "\n",
    "    ##################### Categorical variables #####################\n",
    "    all_cat_vars = ['timesofday','dayofweek','holiday','peak','hour','working_day','season']\n",
    "    cat_vars = [categorical_var for categorical_var in all_cat_vars if categorical_var in predictors]\n",
    "\n",
    "    # categorical variables\n",
    "    cat_pipe = Pipeline([\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "\n",
    "    cat_encoder = 'cat', cat_pipe, cat_vars\n",
    "\n",
    "    ##################### Numerical variables #####################\n",
    "    all_num_vars = ['rain', 'temp', 'rhum','wdsp','temp_r']\n",
    "    num_vars = [numerical_var for numerical_var in all_num_vars if numerical_var in predictors]\n",
    "\n",
    "    num_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "        # ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    num_enconder =  'num', num_pipe, num_vars\n",
    "\n",
    "    ##################### Ordinal variables #####################\n",
    "    # ord_vars = ['wind_speed_group','rainfall_intensity']\n",
    "    all_ord_vars = ['wind_speed_group','rainfall_intensity','temp_bin','rhum_bin']\n",
    "    ord_vars = [ordinal_var for ordinal_var in all_ord_vars if ordinal_var in predictors]\n",
    "\n",
    "    ordinal_cols_mapping = []\n",
    "    if 'wind_speed_group' in predictors:\n",
    "        ordinal_cols_mapping.append(\n",
    "            {\"col\":\"wind_speed_group\",    \n",
    "            \"mapping\": {\n",
    "                'Calm / Light Breeze': 0, \n",
    "                'Breeze': 1, \n",
    "                'Moderate Breeze': 2, \n",
    "                'Strong Breeze / Near Gale': 3, \n",
    "                'Gale / Storm': 4\n",
    "            }}\n",
    "        )\n",
    "\n",
    "    if 'rainfall_intensity' in predictors:\n",
    "        ordinal_cols_mapping.append(\n",
    "            {\"col\":\"rainfall_intensity\",    \n",
    "            \"mapping\": {\n",
    "                'no rain': 0, \n",
    "                'drizzle': 1, \n",
    "                'light rain': 2, \n",
    "                'moderate rain': 3, \n",
    "                'heavy rain': 4\n",
    "            }}\n",
    "        )\n",
    "\n",
    "    # ordinal variables\n",
    "    ord_pipe = Pipeline([\n",
    "        ('ordinal_enconder', ce.OrdinalEncoder(mapping=ordinal_cols_mapping))\n",
    "    ])\n",
    "    \n",
    "    # ord_pipe = 'passthrough'\n",
    "\n",
    "    ord_enconder =  'ordinal_enconder', ord_pipe, ord_vars\n",
    "\n",
    "    #################################################################################\n",
    "\n",
    "    transformers_list = []\n",
    "    transformers_list.append(cat_encoder) if cat_encoder is not None else None\n",
    "    transformers_list.append(ord_enconder) if ord_enconder is not None else None\n",
    "    transformers_list.append(num_enconder) if num_enconder is not None else None\n",
    "    \n",
    "    return ColumnTransformer(transformers=transformers_list, \n",
    "                             remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, columns, X=X_val, y=y_val, plot_title='Feature Importances using permutation'):\n",
    "    #Plotting features importance\n",
    "\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    result = permutation_importance(\n",
    "        model, X[columns], y, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    feat_importances = pd.Series(result.importances_mean, index=columns)\n",
    "    feat_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    sns.barplot(x=feat_importances.values, y=feat_importances.index, orient='h')\n",
    "    plt.title(plot_title)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_rf = et.Idea(idea='Random Forest with all expected features', potential_outcome='To use as a baseline model with all features.')\n",
    "experiment_tracker.new_idea(idea_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['temp_r','rhum','holiday','dayofweek','timesofday','wind_speed_group','rainfall_intensity','peak','working_day']\n",
    "# random forest model\n",
    "params_rf = {'n_estimators': 100,\n",
    "             'max_depth': 10,\n",
    "             'random_state': 42}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor(predictors)),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='squared_error'))\n",
    "])\n",
    "\n",
    "# pipe_rf.fit(X_train[predictors], y_train)\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(pipe_rf, predictors)\n",
    "exp_rf_regr = et.Experiment('Random Forest', predictors=predictors, hyperparameters=pipe_rf['model'].get_params(),\n",
    "                               score=get_metrics_to_Experiment(), notes='Added all predictors and using preprocessing')\n",
    "experiment_tracker.add_experiment(exp_rf_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(model=pipe_rf, columns=predictors,plot_title='Random Forest Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnings = \\\n",
    "\"\"\"Random Forest model with all features has decrease RSME and particularly in validation metrics.\"\"\"\n",
    "experiment_tracker.update_idea(idea_rf, learnings=str.strip(learnings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_rf_cat = et.Idea(idea='Random Forest with all features as categorical', potential_outcome='Changing temp and hum to categorical variables it will improve the model\\\n",
    "    specifically the prediction with boosting trees.')\n",
    "experiment_tracker.new_idea(idea_rf_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['temp_bin','rhum_bin','holiday','dayofweek','timesofday','wind_speed_group','rainfall_intensity','peak','working_day']\n",
    "# random forest model\n",
    "params_rf = {'n_estimators': 100, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor(predictors)),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='squared_error'))\n",
    "])\n",
    "\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(pipe_rf, predictors)\n",
    "exp_rf_regr = et.Experiment('Random Forest', predictors=predictors, hyperparameters=pipe_rf['model'].get_params(),\n",
    "                               score=get_metrics_to_Experiment(), notes='Added all predictors and using preprocessing')\n",
    "experiment_tracker.add_experiment(exp_rf_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(model=pipe_rf, columns=predictors,plot_title='Random Forest Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnings = \\\n",
    "\"\"\"Changing temp and hum into categorical variables did not improve the model. The expected improvement is for boosting models.\"\"\"\n",
    "experiment_tracker.update_idea(idea_rf_cat, learnings=str.strip(learnings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display\n",
    "# from sklearn import set_config\n",
    "# set_config(display='diagram')\n",
    "# display(pipe_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_catboost = et.Idea(idea='Catboost', potential_outcome='Using all features as categorical variables it will perform better using boosting trees.')\n",
    "experiment_tracker.new_idea(idea_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['temp_bin','rhum_bin','holiday','dayofweek','timesofday','wind_speed_group','rainfall_intensity','peak','working_day']\n",
    "# random forest model\n",
    "params_catboost = {'n_estimators': 100,\n",
    "                   'random_state': 42,\n",
    "                   'loss_function': 'RMSE',\n",
    "                   'verbose': 25}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_catboost = Pipeline([\n",
    "    ('preprocessor', preprocessor(predictors)),\n",
    "    ('model', CatBoostRegressor(**params_catboost))\n",
    "])\n",
    "\n",
    "# fitparams_catboost = {'model__eval_set': (X_val[predictors], y_val)}\n",
    "# pipe_catboost.named_steps.model.set_params(eval_set=(X_val, y_val))\n",
    "\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(pipe_catboost, predictors)\n",
    "exp_catboost_regr = et.Experiment('Catboost model', predictors=predictors, hyperparameters=pipe_catboost['model'].get_params(),\n",
    "                               score=get_metrics_to_Experiment(), notes='Added all categoricals features to use Catboost model.')\n",
    "experiment_tracker.add_experiment(exp_catboost_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(model=pipe_catboost, columns=predictors,plot_title='Catboost Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnings = \\\n",
    "\"\"\"Catboost model improved RSME compared to Random Forest (all cat vars) but not as good as Random Forest (temp/hum as numerical feat).\"\"\"\n",
    "experiment_tracker.update_idea(idea_catboost, learnings=str.strip(learnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_svr = et.Idea(idea='SVM Regressor', potential_outcome='SVM Regressor can be a good model for this dataset as it is a linear model and extrapolates well.')\n",
    "experiment_tracker.new_idea(idea_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "predictors = ['temp_bin','rhum_bin','holiday','dayofweek','timesofday','wind_speed_group','rainfall_intensity','peak','working_day']\n",
    "\n",
    "params_svr = {'kernel': 'poly',\n",
    "              'degree': 5,\n",
    "              'gamma': 'scale',\n",
    "              'C': 100\n",
    "              }\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor(predictors)),\n",
    "    ('model', SVR(**params_svr))\n",
    "])\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(pipe_svr, predictors)\n",
    "exp_svr= et.Experiment('Support Vector Regression', predictors=predictors, hyperparameters=pipe_svr['model'].get_params(),\n",
    "                               score=get_metrics_to_Experiment(), notes='')\n",
    "experiment_tracker.add_experiment(exp_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(model=pipe_svr, columns=predictors,plot_title='SVM Regressor Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnings = \\\n",
    "\"\"\"SVM Regressor did not improve the model. Also a few features that it does not seem important on all models, now are, for example Working Day.\n",
    "This model will be discarded as it is not a good model for this dataset.\"\"\"\n",
    "experiment_tracker.update_idea(idea_svr, learnings=str.strip(learnings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_gbm = et.Idea(idea='LightGBM', potential_outcome='Another boosting tree but lighter and known to be more accurate than Catboost.')\n",
    "experiment_tracker.new_idea(idea_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['temp_bin','rhum_bin','holiday','dayofweek','timesofday','wind_speed_group','rainfall_intensity','peak','working_day']\n",
    "\n",
    "# LightGBM model\n",
    "params_lightgbm = {'n_estimators': 100,\n",
    "                   'random_state': 42,\n",
    "                   'metric': 'rmse',\n",
    "                   'verbose': 25\n",
    "                   }\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_lightgbm = Pipeline([\n",
    "    ('preprocessor', preprocessor(predictors)),\n",
    "    ('model', LGBMRegressor(**params_lightgbm))\n",
    "])\n",
    "train_rsme, val_rsme, train_mae, val_mae = get_train_val_score(pipe_lightgbm, predictors)\n",
    "exp_lightgbm = et.Experiment('LightGBM', predictors=predictors, hyperparameters=pipe_lightgbm['model'].get_params(),\n",
    "                               score=get_metrics_to_Experiment(), notes='')\n",
    "experiment_tracker.add_experiment(exp_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(model=pipe_lightgbm, columns=predictors,plot_title='LightGBM Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnings = \\\n",
    "\"\"\"LightGBM model did improve the model on Validation set. The gap between the validation and training set is not large as other models.\"\"\"\n",
    "experiment_tracker.update_idea(idea_gbm, learnings=str.strip(learnings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_tracker.to_excel('experiment_tracker.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Leandro Pessini\" -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Mark\" src=\"./img/GitHub-Mark-64px.png\" style=\"height: 32px; padding-right: 15px\" alt=\"GitHub Mark\" align=\"left\"> [GitHub repository](https://github.com/pessini/moby-bikes) <br>Author: Leandro Pessini"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e88ab788e4c28b6ebfdd315341ca6b84d0235bda4bdece235b181ca971ce4b33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
