{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Octocat\" src='./img/Octocat.jpg' style='height: 60px; padding-right: 15px' alt=\"Octocat\" align=\"left\"> This notebook is part of a GitHub repository: https://github.com/pessini/moby-bikes \n",
    "<br>MIT Licensed\n",
    "<br>Author: Leandro Pessini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Models</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Table of Contents:</p>\n",
    "* [1. Datasets](#1)\n",
    "  * [1.1 Rentals Data - Moby Bikes](#1.1)\n",
    "  * [1.2 Weather Data - Met Ã‰ireann](#1.2)\n",
    "* [2. Preprocessing & Feature Engineering](#2)\n",
    "  * [2.1 Target variable distribution](#2.1)\n",
    "  * [2.2 Missing values](#2.2)\n",
    "  * [2.3 Exploratory Analysis](#2.3)\n",
    "  * [2.4 Features Importance](#2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models & Evaluation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# statsmodel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats as stats\n",
    "\n",
    "# Boost models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cat\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Hyperparameter optimization\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Custom objects\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "import experiment_tracker as et\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 23 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   rain                8760 non-null   float64\n",
      " 1   temp                8760 non-null   float64\n",
      " 2   rhum                8760 non-null   int64  \n",
      " 3   wdsp                8760 non-null   int64  \n",
      " 4   date                8760 non-null   object \n",
      " 5   hour                8760 non-null   int64  \n",
      " 6   day                 8760 non-null   int64  \n",
      " 7   month               8760 non-null   int64  \n",
      " 8   year                8760 non-null   int64  \n",
      " 9   count               8760 non-null   int64  \n",
      " 10  holiday             8760 non-null   bool   \n",
      " 11  dayofweek_n         8760 non-null   int64  \n",
      " 12  dayofweek           8760 non-null   object \n",
      " 13  working_day         8760 non-null   bool   \n",
      " 14  season              8760 non-null   object \n",
      " 15  peak                8760 non-null   bool   \n",
      " 16  timesofday          8760 non-null   object \n",
      " 17  rainfall_intensity  8760 non-null   object \n",
      " 18  wind_bft            8760 non-null   int64  \n",
      " 19  wind_speed_group    8760 non-null   object \n",
      " 20  temp_r              8760 non-null   int64  \n",
      " 21  temp_bin            8760 non-null   float64\n",
      " 22  rhum_bin            8760 non-null   float64\n",
      "dtypes: bool(3), float64(4), int64(10), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/processed/df_train.csv')\n",
    "df_test = pd.read_csv('../data/processed/df_test.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Example of dynamic table with evalution metrics: https://www.kirenz.com/post/2021-12-06-regression-splines-in-python/regression-splines-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OrdinalEnconder\n",
    "# enc_rain = OrdinalEncoder(dtype=np.int64, \\\n",
    "#     categories=[['no rain', 'drizzle', 'light rain', 'moderate rain', 'heavy rain']])\n",
    "# df['rainfall_intensity'] = enc_rain.fit_transform(df[['rainfall_intensity']])\n",
    "\n",
    "# X = df[[c for c in df.columns if c in predictors]]\n",
    "# y = df.pop('count')\n",
    "\n",
    "# num_vars = [n for n in df.select_dtypes(include=['number']).columns if n in predictors] # list comprehension to select only predictors features\n",
    "# cat_vars = [c for c in df.select_dtypes(include=['category']).columns if c in predictors]\n",
    "\n",
    "# dummies = pd.get_dummies(X[cat_vars], drop_first=False)\n",
    "# X = pd.concat([X[num_vars], dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_tracker = et.ExperimentTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Idea added! ---\n",
      "ID#: 5548152816 \n",
      "Idea: Dummy Regressor \n",
      "Potential Outcome: To use as a baseline model, expected to be perform bad\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idea_dummy = et.Idea(idea='Dummy Regressor', potential_outcome='To use as a baseline model, expected to be perform bad')\n",
    "experiment_tracker.new_idea(idea_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Idea updated! ---\n",
      "ID#: 5548152816 \n",
      "Idea: Dummy Regressor \n",
      "Potential Outcome: To use as a baseline model, expected to be perform bad\n",
      "Learnings: Dummy regressor performed bad as expected!!!\n"
     ]
    }
   ],
   "source": [
    "experiment_tracker.update_idea(idea_or_id=5548152816, learnings='Dummy regressor performed bad as expected!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Idea updated! ---\n",
      "ID#: 5548152816 \n",
      "Idea: Dummy Regressor \n",
      "Potential Outcome: To use as a baseline model, expected to be perform bad\n",
      "Learnings: Dummy regressor performed bad as expected!\n"
     ]
    }
   ],
   "source": [
    "experiment_tracker.update_idea(idea_or_id=idea_dummy, learnings='Dummy regressor performed bad as expected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': [],\n",
       " 'ideas': [ID: 5548152816 - Idea: Dummy Regressor - Potential Outcome: To use as a baseline model, expected to be perform bad - Learnings: Dummy regressor performed bad as expected!]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_tracker.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Experiment added! ---\n",
      "ID#: 5551040160 \n",
      "Algorithm: Linear Regression \n",
      "Predictors: [\"temp\",\"rhum\",\"wdsp\"]\n",
      "Hyperparameters: alpha=5\n",
      "Date: 25/05/2022 00:04:15\n",
      "Metric: { 'metric': RSME, 'train': 3.2223,  'validation': 2.2323, 'test': 4.5623 }\n",
      "Notes: Hello there LN!\n"
     ]
    }
   ],
   "source": [
    "rsme = et.Score('RSME', '3.2223', '2.2323', '4.5623')\n",
    "exp_linr = et.Experiment('Linear Regression','[\"temp\",\"rhum\",\"wdsp\"]', 'alpha=5', rsme, 'Hello there LN!')\n",
    "experiment_tracker.add_experiment(exp_linr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Experiment added! ---\n",
      "ID#: 5550927056 \n",
      "Algorithm: Linear Regression \n",
      "Predictors: [\"temp\",\"rhum\",\"wdsp\"]\n",
      "Hyperparameters: alpha=10\n",
      "Date: 25/05/2022 00:04:18\n",
      "Metric: { 'metric': RSME, 'train': 3.2223,  'validation': 2.2323, 'test': 4.5623 }\n",
      "Notes: LN! alpha is 10 now\n"
     ]
    }
   ],
   "source": [
    "exp_linr2 = et.Experiment('Linear Regression','[\"temp\",\"rhum\",\"wdsp\"]', 'alpha=10', rsme, 'LN! alpha is 10 now')\n",
    "experiment_tracker.add_experiment(exp_linr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New Experiment added! ---\n",
      "ID#: 4547328560 \n",
      "Algorithm: Random Forest \n",
      "Predictors: [\"temp\",\"rhum\",\"wdsp\"]\n",
      "Hyperparameters: num_leafs = 5\n",
      "Date: 25/05/2022 00:04:22\n",
      "Metric: [{ 'metric': MAE, 'train': 7482.2,  'validation': 243.23, 'test': 424.523 }, { 'metric': RSM, 'train': 72.2,  'validation': 24.23, 'test': 4.5 }]\n",
      "Notes: Hello there RF!\n"
     ]
    }
   ],
   "source": [
    "mae_rf = et.Score('MAE', '7482.2', '243.23', '424.523')\n",
    "rsm_rf = et.Score('RSM', '72.2', '24.23', '4.5')\n",
    "metrics_rf = [mae_rf,rsm_rf]\n",
    "exp_rf = et.Experiment('Random Forest', '[\"temp\",\"rhum\",\"wdsp\"]', 'num_leafs = 5',metrics_rf,'Hello there RF!')\n",
    "experiment_tracker.add_experiment(exp_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': [Experiment: Linear Regression - Datetime: 25/05/2022 00:04:15 - Notes: Hello there LN!,\n",
       "  Experiment: Linear Regression - Datetime: 25/05/2022 00:04:18 - Notes: LN! alpha is 10 now,\n",
       "  Experiment: Random Forest - Datetime: 25/05/2022 00:04:22 - Notes: Hello there RF!],\n",
       " 'ideas': [ID: 5548152816 - Idea: Dummy Regressor - Potential Outcome: To use as a baseline model, expected to be perform bad - Learnings: Dummy regressor performed bad as expected!]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_tracker.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment #5550927056 removed! ---\n"
     ]
    }
   ],
   "source": [
    "experiment_tracker.remove_experiment(exp_linr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': [Experiment: Linear Regression - Datetime: 25/05/2022 00:04:15 - Notes: Hello there LN!,\n",
       "  Experiment: Random Forest - Datetime: 25/05/2022 00:04:22 - Notes: Hello there RF!],\n",
       " 'ideas': [ID: 5548152816 - Idea: Dummy Regressor - Potential Outcome: To use as a baseline model, expected to be perform bad - Learnings: Dummy regressor performed bad as expected!]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_tracker.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Experiment #4547328560 removed! ---\n"
     ]
    }
   ],
   "source": [
    "experiment_tracker.remove_experiment(4547328560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': [Experiment: Linear Regression - Datetime: 25/05/2022 00:04:15 - Notes: Hello there LN!],\n",
       " 'ideas': [ID: 5548152816 - Idea: Dummy Regressor - Potential Outcome: To use as a baseline model, expected to be perform bad - Learnings: Dummy regressor performed bad as expected!]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_tracker.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdfsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['temp_bin', 'rhum_bin']] = df_train[['temp_bin', 'rhum_bin']].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.copy()\n",
    "predictors = ['temp_bin','wind_speed_group','rhum_bin','rainfall_intensity','holiday','dayofweek','working_day','peak','timesofday']\n",
    "X = df[[c for c in df.columns if c in predictors]]\n",
    "y = df.pop('count')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_vars = ['temp_bin','wind_speed_group','rhum_bin','rainfall_intensity']\n",
    "num_vars = [n for n in df.select_dtypes(include=['number']).columns if n in predictors] # list comprehension to select only predictors features\n",
    "cat_vars = [c for c in df.select_dtypes(include=['object','category','bool']).columns if c in predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical pipeline\n",
    "cat_pipe = Pipeline([\n",
    "    #('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "# Define numerical pipeline\n",
    "num_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "    # ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "ord_pipe = Pipeline([\n",
    "    ('ordinal_enconder', OrdinalEncoder(dtype=np.int64, categories=[['no rain', \n",
    "                                                                     'drizzle', \n",
    "                                                                     'light rain', \n",
    "                                                                     'moderate rain', \n",
    "                                                                     'heavy rain']]))\n",
    "])\n",
    "\n",
    "# Combine categorical and numerical pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipe, cat_vars),\n",
    "    # ('ordinal_enconder', ord_pipe, ord_var),\n",
    "    ('num', num_pipe, num_vars)\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=2022)\n",
    "\n",
    "for n_fold, (train_index, test_index) in enumerate(cv.split(X_train, y_train)):\n",
    "    print('#'*40, f'Fold {n_fold+1} out of {cv.n_splits}', '#'*40)\n",
    "    \n",
    "    # X_train, y_train = X[train_index], y[train_index] # Train data\n",
    "    # X_val, y_val = X[test_index], y[test_index] # Valid data\n",
    "    \n",
    "    # pipe_gbm.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    #           verbose=250, early_stopping_rounds=50)\n",
    "    \n",
    "    # preds_lgb[test_index] += pipe_gbm.predict(X_val, raw_score=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost model\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "# pipe_catboost = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', CatBoostRegressor(verbose=1, n_estimators=100))\n",
    "# ])\n",
    "catboost_model = CatBoostRegressor(n_estimators=5000, depth=3, learning_rate=0.01, loss_function='RMSE')\n",
    "catboost_model.fit(X_train, y_train, cat_features=predictors, eval_set=(X_test, y_test), verbose=250, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = catboost_model.predict(df_test[predictors])\n",
    "y_hat = pd.DataFrame(y_test_pred, columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean_absolute_error(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model\n",
    "params_lightgbm = {'n_estimators': 5000,\n",
    "                   'objective': 'l1',\n",
    "                   'learning_rate': 0.01, \n",
    "                   'subsample': 0.7,\n",
    "                   'verbosity': -1,\n",
    "                   'feature_fraction': 0.5,\n",
    "                   'bagging_fraction': 0.5,\n",
    "                   'bagging_freq': 20,\n",
    "                   'importance_type': 'gain'\n",
    "                   }\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(**params_lightgbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "\n",
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_gbm['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolation problem \n",
    "\n",
    "When using a Random Forest Regressor, the predicted values are never outside the training set values for the target variable. If it is tasked with the problem of predicting for values not previously seen, it will always predict an average of the values seen previously. Obviously the average of a sample can not fall outside the highest and lowest values in the sample. \n",
    "\n",
    "The Random Forest Regressor is unable to discover trends that would enable it in extrapolating values that fall outside the training set. When faced with such a scenario, the regressor assumes that the prediction will fall close to the maximum value in the training set. \n",
    "\n",
    "\n",
    "### Potential solutions\n",
    "\n",
    "Ok, so how can you deal with this extrapolation problem?\n",
    "\n",
    "There are a couple of options:\n",
    "\n",
    "- Use a linear model such as SVM regression, Linear Regression, etc\n",
    "- Build a deep learning model because neural nets are able to extrapolate (they are basically stacked linear regression models on steroids)\n",
    "- Combine predictors using [stacking](https://scikit-learn.org/stable/auto_examples/ensemble/plot_stack_predictors.html). For example, you can create a stacking regressor using a Linear model and a Random Forest Regressor. \n",
    "- Use modified versions of random forest\n",
    "\n",
    "One of such extensions is [Regression-Enhanced Random Forests](https://arxiv.org/pdf/1904.10416.pdf) (RERFs). The authors of this paper propose a technique borrowed from the strengths of penalized parametric regression to give better results in extrapolation problems.\n",
    "\n",
    "Specifically, there are two steps to the process:\n",
    "\n",
    "run Lasso before Random Forest, \n",
    "train a Random Forest on the residuals from Lasso. \n",
    "Since Random Forest is a fully nonparametric predictive algorithm, it may not efficiently incorporate known relationships between the response and the predictors. The response values are the observed values Y1, . . . , Yn  from the training data. RERFs are able to incorporate known relationships between the responses and the predictors which is another benefit of using Regression-Enhanced Random Forests for regression problems.\n",
    "\n",
    "Source: https://neptune.ai/blog/random-forest-regression-when-does-it-fail-and-why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='mae'))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf['model'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_rf['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Random Forest Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance = permutation_importance(pipe_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "sorted_idx\n",
    "# plt.barh(feature_imp[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5,\n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf, criterion='mae'))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "#Plotting features importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(pipe_gbm['model'].feature_importances_,X_train.columns)), \n",
    "                           columns=['Value','Feature'])\n",
    "scaler_ft = MinMaxScaler()\n",
    "feature_imp['Value'] = scaler_ft.fit_transform(feature_imp['Value'].values.reshape(-1,1));\n",
    "\n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('Random Forest Features Importance')\n",
    "locs, labels = plt.xticks()\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest model\n",
    "params_rf = {'n_estimators': 1000, \n",
    "             'max_depth': 20, \n",
    "             'random_state': 0, \n",
    "             'min_samples_split' : 5, \n",
    "             'n_jobs': -1}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**params_rf))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "# y_train_pred = pipe_rf.predict(X_train)\n",
    "# y_test_pred = pipe_rf.predict(X_test)\n",
    "\n",
    "# print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', SVR(kernel='poly',gamma='scale',C=100))\n",
    "])\n",
    "pipe_svr.fit(X_train, y_train)\n",
    "y_train_pred = pipe_svr.predict(X_train)\n",
    "y_test_pred = pipe_svr.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define the model cross-validation configuration\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# evaluate the pipeline using cross validation and calculate MAE\n",
    "scores = cross_val_score(pipe_svr, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "# convert MAE scores to positive values\n",
    "scores = absolute(scores)\n",
    "# summarize the model performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
    "y_test_pred = pipe_svr.predict(X_test)\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = pd.DataFrame()\n",
    "predicted_values['real'] = y_test\n",
    "predicted_values['predicted'] = y_test_pred\n",
    "\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM model\n",
    "params_gbm = {'n_estimators': 150, \n",
    "              'max_depth': 5, \n",
    "              'random_state': 0, \n",
    "              'min_samples_leaf' : 10, \n",
    "              'learning_rate': 0.01, \n",
    "              'subsample': 0.7, \n",
    "              'loss': 'ls'}\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor(**params_gbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "y_train_pred = pipe_gbm.predict(X_train)\n",
    "y_test_pred = pipe_gbm.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM model\n",
    "params_lightgbm = {'n_estimators': 1000, \n",
    "                   'max_depth': 15, \n",
    "                   'random_state': 0, \n",
    "                   'learning_rate': 0.01, \n",
    "                   'subsample': 0.7,\n",
    "                   'num_leaves': 30,\n",
    "                   'metric': 'rmse',\n",
    "                   'n_jobs': 2\n",
    "                   }\n",
    "\n",
    "# Fit a pipeline with transformers and an estimator to the training data\n",
    "pipe_gbm = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LGBMRegressor(**params_lightgbm))\n",
    "])\n",
    "pipe_gbm.fit(X_train, y_train)\n",
    "y_train_pred = pipe_gbm.predict(X_train)\n",
    "y_test_pred = pipe_gbm.predict(X_test)\n",
    "\n",
    "print_evalmetrics(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Leandro Pessini\" -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Mark\" src=\"./img/GitHub-Mark-64px.png\" style=\"height: 32px; padding-right: 15px\" alt=\"GitHub Mark\" align=\"left\"> [GitHub repository](https://github.com/pessini/moby-bikes) <br>Author: Leandro Pessini"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e88ab788e4c28b6ebfdd315341ca6b84d0235bda4bdece235b181ca971ce4b33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
