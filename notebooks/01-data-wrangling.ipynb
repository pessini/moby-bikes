{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32be05c6",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Octocat\" src='./img/Octocat.jpg' style='height: 60px; padding-right: 15px' alt=\"Octocat\" align=\"left\" height=\"60\"> This notebook is part of a GitHub repository: https://github.com/pessini/moby-bikes\n",
    "<br>MIT Licensed\n",
    "<br>Author: Leandro Pessini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee0606",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Data Wrangling</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c43813",
   "metadata": {},
   "source": [
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">Table of Contents:</p>\n",
    "* [1. Datasets](#1)\n",
    "  * [1.1 Rentals Data - Moby Bikes](#1.1)\n",
    "  * [1.2 Weather Data - Met Éireann](#1.2)\n",
    "* [2. Preprocessing & Feature Engineering](#2)\n",
    "  * [2.1 Target variable distribution](#2.1)\n",
    "  * [2.2 Missing values](#2.2)\n",
    "  * [2.3 Exploratory Analysis](#2.3)\n",
    "  * [2.4 Features Importance](#2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77876c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf28ed8",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">1- Datasets</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469247f",
   "metadata": {},
   "source": [
    "Dataset provided by [Moby Bikes](https://data.gov.ie/dataset/moby-bikes) through a public [API](https://data.smartdublin.ie/mobybikes-api). \n",
    "\n",
    "Dataset provided by [Met Éireann](https://www.met.ie/) through a public [API](https://data.gov.ie/organization/meteireann).\n",
    "\n",
    "\n",
    "[Met Éireann Weather Forecast API](https://data.gov.ie/dataset/met-eireann-weather-forecast-api/resource/5d156b15-38b8-4de9-921b-0ffc8704c88e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d555c83",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "\n",
    "## Rentals Data - Moby Bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce88361",
   "metadata": {},
   "source": [
    "### MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "from conn import mongodb\n",
    "import importlib\n",
    "from pymongo import MongoClient\n",
    "from urllib.parse import quote_plus\n",
    "importlib.reload(mongodb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _connect_mongo(host, port, username, password, db_name):\n",
    "    \"\"\" A util for making a connection to mongo \"\"\"\n",
    "\n",
    "    if username and password:\n",
    "        try:\n",
    "            mongo_uri = f'mongodb://{username}:{quote_plus(password)}@{host}:{port}/{db_name}'\n",
    "            conn = MongoClient(mongo_uri)\n",
    "        except:\n",
    "            print('Could not connect to MongoDB')\n",
    "    else:\n",
    "        conn = MongoClient(host, port)\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e378473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mongo(query={}, collection='', no_id=True):\n",
    "    \"\"\" Read from Mongo and Store into a DataFrame \"\"\"\n",
    "    df = None\n",
    "    try:\n",
    "        # Connect to MongoDB\n",
    "        conn = _connect_mongo(host=mongodb.host, port=mongodb.port, username=mongodb.user_name, password=mongodb.pass_word, db_name=mongodb.db_name)\n",
    "        db = conn.mobybikes # switch to the database\n",
    "\n",
    "        if collection in db.list_collection_names():\n",
    "            \n",
    "            # Make a query to the specific DB and Collection and store into a Dataframe\n",
    "            data = db[collection].find(query)\n",
    "            df =  pd.DataFrame(list(data))\n",
    "            \n",
    "            # Delete the _id\n",
    "            if no_id:\n",
    "                del df['_id']\n",
    "        else:\n",
    "            print(f'Collection {collection} was not found!')\n",
    "            pass\n",
    "\n",
    "        # close mongodb connection\n",
    "        conn.close()\n",
    "    except:\n",
    "        print('Could not query MongoDB')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a61d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_data = read_mongo(collection='historical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa07f34",
   "metadata": {},
   "source": [
    "### Dataset (csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a546e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv('../data/raw/combined_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f81e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.columns = historical_data.columns.str.lower()\n",
    "historical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6630f2",
   "metadata": {},
   "source": [
    "<a id=\"1.2\"></a>\n",
    "\n",
    "## Weather Data - Met Éireann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b31d46",
   "metadata": {},
   "source": [
    "About the weather data there are two important decisions. One is about from **which station** the **historical data will be collected** and the other one is about the **frequency of data**, which can be **hourly or daily**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89830979",
   "metadata": {},
   "source": [
    "### Station Name: **PHOENIX PARK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cde297",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenixpark_weather_hourly = pd.read_csv('../data/raw/hly175.csv')\n",
    "phoenixpark_weather_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116806c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenixpark_weather_daily = pd.read_csv('../data/raw/dly175.csv')\n",
    "phoenixpark_weather_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d825e",
   "metadata": {},
   "source": [
    "### Station Name: **DUBLIN AIRPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec59eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_airport_weather_hourly = pd.read_csv('../data/raw/hly532.csv')\n",
    "dublin_airport_weather_hourly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdd58c",
   "metadata": {},
   "source": [
    "### Phoenix Park Station vs Dublin Aiport Station\n",
    "Geographically, the station at Phoenix Park would be the most suitable choice but unfortunately, they do not collect Wind information which in Ireland plays an important role when deciding to go cycling or not. For those who are not familiar with Irish weather, it rains a lot and mostly we do not have much choice about it but the wind is something that can prevent you go outside or choose a different kind of transport. Heavy rain is kind of rare on the other hand.\n",
    "\n",
    "### Hourly vs Daily data\n",
    "On this subject, daily data for the business would make more sense but because the weather is so unpredictable in Ireland (it can completely change in an hour), the best option would be hourly especially if we are looking at a historical perspective. For simplicity and better planning, we can always aggregate the predicted results by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_airport_weather_hourly['date'] = pd.to_datetime(dublin_airport_weather_hourly['date'])\n",
    "dublin_airport_weather_hourly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89adbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_airport_weather_hourly.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b2c10",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c325a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_hist = datetime(2021, 2, 1) # first day\n",
    "end_date_hist = datetime(2021, 8, 31) # last day used as historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_dubairport_data = dublin_airport_weather_hourly.copy()\n",
    "recent_dubairport_data = recent_dubairport_data[(recent_dubairport_data.date >= start_date_hist) & (recent_dubairport_data.date <= end_date_hist)]\n",
    "len(dublin_airport_weather_hourly), len(recent_dubairport_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5870fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['ind','ind.1','ind.2','ind.3','vappr','msl','ind.4','wddir','ww','w','sun','vis','clht','clamt']\n",
    "weather_data = recent_dubairport_data.drop(columns=columns_to_drop)\n",
    "weather_data.to_csv('../data/interim/hist_weather_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0075e",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"font-size:100%; text-align:left; color:#444444;\">2- Preprocessing & Feature Engineering</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c83d5",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "Hourly trend: There must be high demand during office timings. Early morning and late evening can have different trend (cyclist) and low demand during 10:00 pm to 4:00 am.\n",
    "\n",
    "Daily Trend: Registered users demand more bike on weekdays as compared to weekend or holiday.\n",
    "\n",
    "Rain: The demand of bikes will be lower on a rainy day as compared to a sunny day. Similarly, higher humidity will cause to lower the demand and vice versa.\n",
    "\n",
    "Temperature: In Ireland, temperature has positive correlation with bike demand.\n",
    "\n",
    "Traffic: It can be positively correlated with Bike demand. Higher traffic may force people to use bike as compared to other road transport medium like car, taxi etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28849bd5",
   "metadata": {},
   "source": [
    "### New Features\n",
    "- date (yyyy-mm-dd)\n",
    "- month\n",
    "- hour\n",
    "- workingday\n",
    "- peak\n",
    "- holiday\n",
    "- season\n",
    "- battery_start\n",
    "- battery_end\n",
    "- path? (multi polygon)\n",
    "- rental_duration\n",
    "\n",
    "\n",
    "The number of rentals each hour will be aggregate later with a new feature `count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239df5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals_data = historical_data.drop(['harvesttime','ebikestateid'], axis=1).copy()\n",
    "rentals_data[[\"lastgpstime\", \"lastrentalstart\"]] = rentals_data[[\"lastgpstime\", \"lastrentalstart\"]].apply(pd.to_datetime)\n",
    "\n",
    "rentals_data = rentals_data.astype({'battery': np.int16}, errors='ignore') # errors ignore to keep missing values (not throwing error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdae135",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55275ed7",
   "metadata": {},
   "source": [
    "### Rentals' information\n",
    "\n",
    "- `coordinates`: converting latitude and longitude to an array to store a GeoJSON object *MultiPoint* \n",
    "- `start_battery`: getting the battery status when the rental started\n",
    "- `lastgpstime`: new variable that will only store the last record when grouping rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(x):\n",
    "    d = {}\n",
    "    d['coordinates'] = x[['latitude','longitude']].values.tolist()\n",
    "    d['start_battery'] = list(x['battery'])[-1] # get the first battery status (when rental started)\n",
    "    d['lastgpstime'] = list(x['lastgpstime'])[0] # get the last gpstime (previously sorted)\n",
    "    \n",
    "    return pd.Series(d, index=['coordinates', 'start_battery', 'lastgpstime'])\n",
    "\n",
    "# also sorting data by lastgpstime\n",
    "grouped_rentals = rentals_data.sort_values(\"lastgpstime\", ascending=False).groupby(['lastrentalstart', 'bikeid']).apply(feat_eng).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8541b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e61f82f",
   "metadata": {},
   "source": [
    "### Date and time - new features\n",
    "- `rental_date`\n",
    "- `rental_month`\n",
    "- `rental_hour`\n",
    "- `holiday`\n",
    "- `workingday`\n",
    "- `peak`\n",
    "- `season`: (1 = Spring, 2 = Summer, 3 = Fall, 4 = Winter)\n",
    "- *`duration`: duration of the rental\n",
    "\n",
    "\\* **Assumption**: Due to lack of information and data, to calculate the average rent time I am assuming that when a new bike rental starts the average will be calculated by: $ ( AvgRentTime* = LastGPSTime - LastRentalStart ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af575e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals['rental_date'] = pd.to_datetime(grouped_rentals['lastrentalstart'].dt.date)\n",
    "grouped_rentals['rental_month'] = grouped_rentals['lastrentalstart'].dt.month\n",
    "grouped_rentals['rental_hour'] = grouped_rentals['lastrentalstart'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355516b2",
   "metadata": {},
   "source": [
    "Slicing the dataset to get the sample as per weather data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2602229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals = grouped_rentals[(grouped_rentals.rental_date >= start_date_hist) & (grouped_rentals.rental_date <= end_date_hist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43147d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time of rental in minutes (lastgpstime - rental-start)\n",
    "grouped_rentals['duration'] = (grouped_rentals['lastgpstime'] - grouped_rentals['lastrentalstart']) / pd.Timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c2331",
   "metadata": {},
   "source": [
    "A few GPS records have frozen and stopped sending the accurate data back. About 345 records which would lead to a bias duration of rentals.\n",
    "\n",
    "To prevent any inaccurate information these records will be set as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ca524",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals['duration'] = np.where(grouped_rentals['duration'] < 0, np.NaN, grouped_rentals['duration'])\n",
    "len(grouped_rentals[ np.isnan(grouped_rentals['duration']) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3df2e",
   "metadata": {},
   "source": [
    "## Bank Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "qry_bh = {\n",
    "    'type': 'National holiday'\n",
    "}\n",
    "\n",
    "bank_holidays = read_mongo(query=qry_bh, collection='irishcalendar')\n",
    "bank_holidays.drop(['country', 'type'], axis=1, inplace=True)\n",
    "bank_holidays['date'] = pd.DatetimeIndex(bank_holidays['date'].apply(pd.to_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2595b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# holiday\n",
    "grouped_rentals['holiday'] = grouped_rentals['rental_date'].isin(bank_holidays['date'])\n",
    "\n",
    "# day of the week\n",
    "grouped_rentals['dayofweek'] = grouped_rentals['rental_date'].dt.dayofweek\n",
    "\n",
    "# working day (Monday=0, Sunday=6)\n",
    "grouped_rentals['working_day'] = grouped_rentals['dayofweek'] < 5 # from 0 to 4 or monday to friday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd71c793",
   "metadata": {},
   "source": [
    "## Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 2000 # dummy leap year to allow input X-02-29 (leap day)\n",
    "seasons = [(3, (datetime(Y,  1,  1),  datetime(Y,  3, 20))),\n",
    "           (0, (datetime(Y,  3, 21),  datetime(Y,  6, 20))),\n",
    "           (1, (datetime(Y,  6, 21),  datetime(Y,  9, 22))),\n",
    "           (2, (datetime(Y,  9, 23),  datetime(Y, 12, 20))),\n",
    "           (3, (datetime(Y, 12, 21),  datetime(Y, 12, 31)))]\n",
    "\n",
    "def get_season(date: pd.DatetimeIndex) -> int:\n",
    "    '''\n",
    "        Receives a date and returns the corresponded season\n",
    "        0 - Spring | 1 - Summer | 2 - Autumn | 3 - Winter\n",
    "        Vernal equinox(about March 21): day and night of equal length, marking the start of spring\n",
    "        Summer solstice (June 20 or 21): longest day of the year, marking the start of summer\n",
    "        Autumnal equinox(about September 23): day and night of equal length, marking the start of autumn\n",
    "        Winter solstice (December 21 or 22): shortest day of the year, marking the start of winter\n",
    "    '''\n",
    "    date = date.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons if start <= date <= end)\n",
    "\n",
    "\n",
    "grouped_rentals['season'] = grouped_rentals.rental_date.map(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals.groupby('season').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d329dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5ebc7",
   "metadata": {},
   "source": [
    "## Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eeaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals['start_battery'] = pd.to_numeric(grouped_rentals['start_battery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals[grouped_rentals['start_battery'] > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39c288",
   "metadata": {},
   "source": [
    "From the battery records there is a few cases that we can consider. Only one record has `> 100` and a few negatives ones. To simplify the analysis the records will be normalized with values between `0 > x > 100`.\n",
    "\n",
    "All missing values (*n=571*) will not be transformed as it could be only malfunction issue when transmiting the data and it could mislead the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f4b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize battery status between 0 > x < 100\n",
    "grouped_rentals['start_battery'] = abs(grouped_rentals['start_battery'])\n",
    "grouped_rentals.loc[grouped_rentals['start_battery'] > 100, 'start_battery'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b33cf3",
   "metadata": {},
   "source": [
    "## Peak Times\n",
    "\n",
    ">https://www.independent.ie/irish-news/the-new-commuter-hour-peak-times-increase-with-record-traffic-volumes-36903431.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9da377",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_rentals['peak'] = grouped_rentals[['rental_hour', 'working_day']] \\\n",
    "    .apply(lambda x: (0, 1)[(x['working_day'] == 1 and (6 <= x['rental_hour'] <= 10 or 15 <= x['rental_hour'] <= 19))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rentals = grouped_rentals.copy()\n",
    "new_rentals.to_csv('../data/interim/new_features_rentals.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c3956",
   "metadata": {},
   "source": [
    "## Humidity\n",
    "\n",
    "Attempt to create a new feature called `Humidity` to avoid Multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf625434",
   "metadata": {},
   "source": [
    "### We need different humidity quantities\n",
    "\n",
    "The problem with relative humidity is that, by itself, it doesn’t really tell you how humid it is.\n",
    "\n",
    "- **Relative Humidity** – This quantity tells us how close the conditions are to saturation, when condensation of water vapor can occur. The interaction of porous materials with water vapor increases with increasing RH. The chance of growing mold increases with increasing RH, 70% usually given as the threshold to stay below.\n",
    "- **Dew Point Temperature** – This temperature scales with the amount of water vapor. As more water vapor enters a volume, the dew point goes up. If the air in your crawl space, for example, has a dew point of 75° F, you’re probably going to find condensation somewhere. Look at the water pipes, poorly insulated ducts, and uninsulated duct boots.\n",
    "- **Wet Bulb Temperature** – If dew point is the temperature of condensation, wet bulb is the temperature of evaporation. Same concept; different direction. This one’s important for cooling our bodies.\n",
    "\n",
    "Once you get a handle on these three quantities, you’ll have a pretty good understanding of humidity.\n",
    "\n",
    "> https://www.energyvanguard.com/blog/problem-with-relative-humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['rhum'] = pd.to_numeric(weather_data['rhum'],errors = 'coerce')\n",
    "weather_data['wetb'] = pd.to_numeric(weather_data['wetb'],errors = 'coerce')\n",
    "weather_data['dewpt'] = pd.to_numeric(weather_data['dewpt'],errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffce8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data[weather_data.rhum.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d7fec",
   "metadata": {},
   "source": [
    "### Variance Inflation Factor(VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878313a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa65439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values: 'ffill' -> propagate last valid observation forward to next valid\n",
    "weather_data.fillna(method=\"ffill\", inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ecc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vif = weather_data.copy().drop('date', axis=1)\n",
    "#Calculate VIF for each variable in the new data frame\n",
    "vif = pd.DataFrame()\n",
    "vif[\"features\"] = test_vif.columns\n",
    "vif[\"vif_value\"] = [variance_inflation_factor(test_vif.values, i) for i in range(test_vif.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1d10c",
   "metadata": {},
   "source": [
    "To avoid multicolinearity we could create a new feature based on some calculation on those three features related to humidity. Unfortunately, the Forecast API that will be used in production **does not include Wet Bulb Temperature**.\n",
    "\n",
    "There are a few equations that could applied to calculate Wet Bulb Temperature (eg: Stull formula) but because we do not have which one is used to store this feature on their historical the best would be not use this feature at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2cd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather_data.drop(['rhum', 'wetb', 'dewpt'], axis=1, inplace=True)\n",
    "weather_data.drop(['wetb', 'dewpt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd192a57",
   "metadata": {},
   "source": [
    "## Combining Rentals and Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals = new_rentals.copy()\n",
    "weather = weather_data.copy()\n",
    "\n",
    "weather['rental_date'] = pd.to_datetime(weather['date'].dt.date)\n",
    "weather['rental_hour'] = weather['date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1291989",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(rentals, weather, on=['rental_date', 'rental_hour'])\n",
    "all_data.to_csv('../data/interim/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dee8ca",
   "metadata": {},
   "source": [
    "## Grouping data to reflect hourly count of rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8245ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_rentals = all_data.copy()\n",
    "count_hourly_rentals = hourly_rentals.groupby(['rental_date', 'rental_hour']).size().reset_index(name='count')\n",
    "columns_to_drop = ['lastrentalstart','bikeid','coordinates','start_battery','lastgpstime','rental_month','duration','date']\n",
    "hourly_rentals = hourly_rentals.drop(columns_to_drop, axis=1).drop_duplicates(subset=['rental_date', 'rental_hour'])\n",
    "hourly_rentals.shape, count_hourly_rentals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea66157",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_data = pd.merge(hourly_rentals, count_hourly_rentals, on=['rental_date','rental_hour'])\n",
    "hourly_data.to_csv('../data/interim/hourly_data.csv', index=False)\n",
    "hourly_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf35db",
   "metadata": {},
   "source": [
    "<img title=\"GitHub Mark\" src=\"./img/GitHub-Mark-64px.png\" style=\"height: 32px; padding-right: 15px\" alt=\"GitHub Mark\" align=\"left\"> [GitHub repository](https://github.com/pessini/moby-bikes) <br>Author: Leandro Pessini"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c82cf216bcd6695c751af4e033b89e10a78cc5d50e2943f0ed5dd08b475eddb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
